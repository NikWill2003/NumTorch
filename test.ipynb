{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9225817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Union, Tuple, Self, Iterable\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import wandb\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c182ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular constants\n",
    "RNG = np.random.default_rng()\n",
    "DTYPE = 'float32' \n",
    "\n",
    "proc  = psutil.Process(os.getpid())\n",
    "\n",
    "# testing constants\n",
    "if DTYPE=='float64':\n",
    "    EPS, ATOL, RTOL = 1e-6, 1e-5, 1e-3\n",
    "else:\n",
    "    EPS, ATOL, RTOL = 1e-4, 1e-4, 1e-2\n",
    "K = 20\n",
    "\n",
    "dtype_eps = {'float16': 1e-4,\n",
    "             'float32': 1e-7,\n",
    "             'float64': 1e-15}[DTYPE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "561019e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor():\n",
    "    def __init__(self, data, requires_grad=False, children=(), op=''):\n",
    "        self.data: np.ndarray = np.array(data, dtype=DTYPE)\n",
    "        self.grad = np.zeros_like(data, dtype=DTYPE)\n",
    "        self.requires_grad = requires_grad\n",
    "        self._prev = set(children)\n",
    "        self._backward = lambda : None\n",
    "        self._op = op\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> Tuple[int]:\n",
    "        return self.data.shape\n",
    "    \n",
    "    @property\n",
    "    def size(self) -> int: \n",
    "        return self.data.size\n",
    "    \n",
    "    def zero_grad(self) -> None:\n",
    "        self.grad = np.zeros_like(self.data, dtype=DTYPE)\n",
    "\n",
    "    def item(self) -> np.ndarray:\n",
    "        return self.data\n",
    "    \n",
    "    def _unbroadcast(self, grad: np.ndarray) -> np.ndarray:\n",
    "        dims_to_remove = tuple(i for i in range(len(grad.shape) - len(self.shape))) \n",
    "        # remove prepended padding dimensions\n",
    "        grad = np.sum(grad, axis=dims_to_remove, keepdims=False) \n",
    "        dims_to_reduce = tuple(i for i, (d1,d2) in enumerate(zip(grad.shape, self.shape)) if d1!=d2)\n",
    "        # reduce broadcasted dimensions\n",
    "        return np.sum(grad, axis=dims_to_reduce, keepdims=True)\n",
    "\n",
    "    # need to build topo graph and then go through it and call backwards on each of the tensors\n",
    "    def backward(self) -> None:\n",
    "        self.grad = np.ones_like(self.data)\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        # do DFS on un-visited nodes, add node to topo-when all its children have been visited\n",
    "        def build_topo(node):\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                for child in node._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(node)\n",
    "        build_topo(self)\n",
    "\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "            node._prev = set(())\n",
    "            node._backward = lambda : None\n",
    "\n",
    "    def __getitem__(self, indexes):\n",
    "        out = Tensor(self.data[indexes], self.requires_grad, (self), 'slice')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                pass\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "            \n",
    "    def __add__(self, rhs) -> \"Tensor\":\n",
    "        rhs = rhs if isinstance(rhs, Tensor) else Tensor(rhs)\n",
    "        out = Tensor(self.data + rhs.data, self.requires_grad or rhs.requires_grad, (self, rhs), '+')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad += self._unbroadcast(out.grad)\n",
    "            if rhs.requires_grad:\n",
    "                rhs.grad += rhs._unbroadcast(out.grad)\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __neg__(self) -> \"Tensor\":\n",
    "        out = Tensor(-self.data, self.requires_grad, (self,), 'neg')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad += -out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __sub__(self, rhs) -> \"Tensor\":\n",
    "        return self + (-rhs)\n",
    "\n",
    "    def __mul__(self, rhs) -> \"Tensor\":\n",
    "        rhs = rhs if isinstance(rhs, Tensor) else Tensor(rhs)\n",
    "        out = Tensor(self.data*rhs.data, self.requires_grad or rhs.requires_grad, (self, rhs), f'*')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad += self._unbroadcast(out.grad * rhs.data)\n",
    "            if rhs.requires_grad:\n",
    "                rhs.grad += rhs._unbroadcast(out.grad * self.data)\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "        \n",
    "    def __truediv__(self, rhs) -> \"Tensor\":\n",
    "        return self * (rhs**-1)\n",
    "    \n",
    "    # TODO add check for rhs, if epxponent if negative the gradient is undefined\n",
    "    def __pow__(self, rhs) -> \"Tensor\": \n",
    "        rhs = rhs if isinstance(rhs, Tensor) else Tensor(rhs)\n",
    "        lhs_is_neg = self.data < 0\n",
    "        rhs_is_frac = ~np.isclose(rhs.data % 1, 0)\n",
    "        if np.any(lhs_is_neg & rhs_is_frac):\n",
    "            raise ValueError('cannot raise negative value to a decimal power')\n",
    "        \n",
    "        out = Tensor(self.data**rhs.data, self.requires_grad or rhs.requires_grad, (self,), f'**')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad += self._unbroadcast(out.grad * ((rhs.data)*(self.data**(rhs.data-1))))\n",
    "            if rhs.requires_grad:\n",
    "                rhs.grad += rhs._unbroadcast(out.grad * (self.data ** rhs.data) * np.log(self.data))\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    '''data shape: (da, ..., d2, d1, n, k) rhs shape: (ob, ..., o2, o1, k, m)\n",
    "       inputs are broadcast so that they have the same shape by expanding along\n",
    "       dimensions if possible, out shape: (tc, ..., t2, t1, n, m), where ti = max(di, oi)\n",
    "       if di or oi does not exist it is treated as 1, and c = max d, a\n",
    "       if self is 1d shape is prepended with a 1, for rhs it would be appended'''\n",
    "    def __matmul__(self, rhs) -> \"Tensor\":\n",
    "        rhs = rhs if isinstance(rhs, Tensor) else Tensor(rhs)\n",
    "        out = Tensor(self.data @ rhs.data, self.requires_grad or rhs.requires_grad, (self, rhs), '@')\n",
    "\n",
    "        def _backward():\n",
    "            A, B, = self.data, rhs.data\n",
    "            g = out.grad\n",
    "            # broadcast 1d arrays to be 2d \n",
    "            A2 = A.reshape(1, -1) if len(A.shape) == 1 else A\n",
    "            B2 = B.reshape(-1, 1) if len(B.shape) == 1 else B\n",
    "            # extend g to have reduced dims\n",
    "            g = np.expand_dims(g, -1) if len(B.shape) == 1 else g\n",
    "            g = np.expand_dims(g, -2) if len(A.shape) == 1 else g\n",
    "            # transpose last 2 dimensions, as matmul treats tensors as batched matricies\n",
    "            if self.requires_grad:\n",
    "                self.grad += self._unbroadcast(g @ B2.swapaxes(-2, -1))\n",
    "            if rhs.requires_grad:\n",
    "                rhs.grad += rhs._unbroadcast(A2.swapaxes(-2, -1) @ g)\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def relu(self) -> \"Tensor\":\n",
    "        out = Tensor((self.data > 0) * self.data, self.requires_grad, (self,), 'Relu')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad += (self.data > 0) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def log(self) -> \"Tensor\":\n",
    "        if np.any(self.data < 0):\n",
    "            raise ValueError('cannot log negative values')\n",
    "        out = Tensor(np.log(self.data), self.requires_grad, (self,), 'log')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad += (1 / self.data) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def exp(self) -> \"Tensor\":\n",
    "        out = Tensor(np.exp(self.data), self.requires_grad, (self,), 'exp')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                self.grad += np.exp(self.data) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def sum(self, axis=None, keepdims=False) -> \"Tensor\":\n",
    "        out = Tensor(np.sum(self.data, axis=axis, keepdims=keepdims), self.requires_grad, (self,), 'sum')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                g = np.expand_dims(out.grad, axis) if (axis is not None and not keepdims) else out.grad\n",
    "                self.grad += g\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def mean(self, axis=None) -> \"Tensor\":\n",
    "        out = Tensor(np.mean(self.data, axis=axis), self.requires_grad, (self,), 'mean')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                N =  self.size // out.size \n",
    "                g = np.expand_dims(out.grad, axis) if axis is not None else out.grad\n",
    "                self.grad += g / N\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def clamp(self, a_min=None, a_max=None):\n",
    "        out = Tensor(np.clip(self.data, a_min=a_min, a_max=a_max), self.requires_grad, (self,), 'clamp')\n",
    "\n",
    "        def _backward():\n",
    "            if self.requires_grad:\n",
    "                mask = (self.data > a_min) if a_min is not None else np.ones_like(self.data)\n",
    "                mask = mask & (self.data < a_max) if a_max is not None else mask\n",
    "                self.grad += out.grad * mask\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __radd__(self, lhs) -> \"Tensor\":\n",
    "        return self + lhs\n",
    "    \n",
    "    def __rsub__(self, lhs) -> \"Tensor\":\n",
    "        return self + lhs\n",
    "    \n",
    "    def __rmul__(self, lhs) -> \"Tensor\":\n",
    "        return self * lhs\n",
    "    \n",
    "    def __rtruediv__(self, lhs) -> \"Tensor\":\n",
    "        return Tensor(lhs) / self\n",
    "    \n",
    "    def __rpow__(self, lhs) -> \"Tensor\":\n",
    "        return Tensor(lhs) ** self\n",
    "    \n",
    "    def __rmatmul__(self, lhs) -> \"Tensor\":\n",
    "        return Tensor(lhs) @ self\n",
    "    \n",
    "    @classmethod\n",
    "    def random(cls, shape: tuple, bounds = (0,1), requires_grad=False) -> \"Tensor\":\n",
    "        lower, upper = bounds\n",
    "        data = RNG.random(shape, dtype=DTYPE)*(upper-lower) + lower\n",
    "        return cls(data, requires_grad=requires_grad)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'tensor shape: {self.shape}, op:{self._op}'        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f977fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter(Tensor):\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data, requires_grad=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def kaiming(cls, fan_in, shape):\n",
    "        std = np.sqrt(2/fan_in)\n",
    "        weights = (RNG.standard_normal(shape, dtype='float64')*std).astype(dtype=DTYPE)\n",
    "        return cls(weights)\n",
    "    \n",
    "    @classmethod\n",
    "    def zeros(cls, shape):\n",
    "        return cls(np.zeros(shape, dtype=DTYPE))\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'parameter shape: {self.shape}, size: {self.size}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9103a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class Module():\n",
    "    \n",
    "    def __call__(self, input: Tensor) -> Tensor:\n",
    "        return self.forward(input)\n",
    "    \n",
    "    @property\n",
    "    def modules(self) -> list[\"Module\"]:\n",
    "        modules: list[Module] = []\n",
    "        for value in self.__dict__.values():\n",
    "            if isinstance(value, Module):\n",
    "                modules.append(value)\n",
    "\n",
    "            elif isinstance(value, dict):\n",
    "                for v in value.values():\n",
    "                    if isinstance(v, Module):\n",
    "                        modules.append(v)\n",
    "\n",
    "            elif isinstance(value, Iterable) and not isinstance(value, (str, bytes)):\n",
    "                for v in value:\n",
    "                    if isinstance(v, Module):\n",
    "                        modules.append(v)\n",
    "                    \n",
    "        return modules\n",
    "    \n",
    "    @property\n",
    "    def params(self) -> list[Parameter]:\n",
    "        immediate_params = [attr for attr in self.__dict__.values() \n",
    "                                    if isinstance(attr, Parameter)]\n",
    "        modules_params = [param for module in self.modules \n",
    "                                    for param in module.params]\n",
    "        return immediate_params + modules_params\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        pass\n",
    "    \n",
    "    def zero_grad(self) -> None:\n",
    "        for param in self.params:\n",
    "            param.zero_grad()\n",
    "\n",
    "    def train(self) -> None:\n",
    "        for param in self.params:\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for module in self.modules:\n",
    "            if isinstance(module, DynamicModule):\n",
    "                module.mode = 'train'\n",
    "        \n",
    "    def eval(self) -> None:\n",
    "        for param in self.params:\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for module in self.modules:\n",
    "            if isinstance(module, DynamicModule):\n",
    "                module.mode = 'eval'\n",
    "\n",
    "class Sequential(Module):\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        x = input\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class Affine(Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.A = Parameter.kaiming(in_dim, (in_dim, out_dim))\n",
    "        self.b = Parameter.zeros((out_dim))\n",
    "\n",
    "    def forward(self, input: Tensor):\n",
    "        x = input\n",
    "        # x: (B, in), A : (in, out), B: out\n",
    "        return (x @ self.A) + self.b\n",
    "    \n",
    "class DynamicModule(Module):\n",
    "    def __init__(self) -> None:\n",
    "        self.mode = 'train'\n",
    "\n",
    "class DropOut(DynamicModule):\n",
    "    def __init__(self, p):\n",
    "        self.mode = 'train'\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        if self.mode == 'eval':\n",
    "            return x * (1-self.p) # have to rescale during inference\n",
    "        mask_idx_nums = RNG.choice(x.size, size=int(x.size*(1-self.p)), replace=False)\n",
    "        mask_idxs = np.unravel_index(mask_idx_nums, x.shape)\n",
    "        mask = np.zeros_like(x.data)\n",
    "        mask[mask_idxs] = 1\n",
    "        \n",
    "        return x * mask\n",
    "    \n",
    "    '''TODO: can implement in the furture to make it faster once __getitem__ is implemented'''\n",
    "    # def forward(self, x: Tensor):\n",
    "    #     if self.mode == 'eval':\n",
    "    #         return x * (1-self.p) # have to rescale during inference\n",
    "    #     mask_idx_nums = RNG.choice(x.size, size=int(x.size*self.p), replace=False)\n",
    "    #     mask_idxs = np.unravel_index(mask_idx_nums, x.shape)\n",
    "    #     x.data[mask_idxs] = 0\n",
    "        \n",
    "    #     return x\n",
    "\n",
    "\n",
    "class Relu(Module):\n",
    "    def forward(self, x: Tensor):\n",
    "        return x.relu()\n",
    "    \n",
    "class SoftMax(Module):\n",
    "    def forward(self, x: Tensor):\n",
    "        # temporary as max is not an implemented op\n",
    "        x = x - np.max(x.data, axis=-1, keepdims=True) # for numerical stability \n",
    "        x = x.exp()\n",
    "        norm_c = x.sum(axis=-1, keepdims=True)\n",
    "        return x / norm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b070de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "do = DropOut(0.5)\n",
    "x = Tensor.random((2,3))\n",
    "# print(A, do(A))\n",
    "mask_idx_nums = RNG.choice(x.size, size=int(x.size*(1-0.5)), replace=False)\n",
    "mask_idxs = np.unravel_index(mask_idx_nums, x.shape)\n",
    "mask = np.zeros_like(x.data)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a67cdb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(array, num_c):\n",
    "    one_hot = np.zeros(shape=(array.size, num_c))\n",
    "    for idx, i in enumerate(array):\n",
    "        one_hot[idx, i] = 1\n",
    "    return one_hot\n",
    "\n",
    "class Loss_Fn():\n",
    "    def __call__(self, *args, **kwargs) -> Tensor:\n",
    "        raise NotImplementedError(\"Loss function must implement __call__ method\")\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}()'\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.__repr__()\n",
    "\n",
    "class SoftMaxCrossEntropy(Loss_Fn):\n",
    "    def __call__(self, z: Tensor, y) -> Tensor:\n",
    "        '''logits z, shape (B, C), true integer lables y, shape (B)'''\n",
    "        # TODO change from manual one hot encoding when getitem is implemented in tensor\n",
    "        y = Tensor(one_hot_encode(y, z.shape[-1])) #shape (B, C)\n",
    "        z = z - np.max(z.data, axis=-1, keepdims=True) # for numerical stability \n",
    "        loss = (-(z * y).sum(axis=-1) + ((z.exp()).sum(axis=-1)).log()).mean()\n",
    "        return loss\n",
    "\n",
    "class CrossEntropy(Loss_Fn):\n",
    "    def __call__(self, q: Tensor, y) -> Tensor:\n",
    "        '''pred q, shape (B, C), true integer lables y, shape (B)'''\n",
    "        # TODO change from manual one hot encoding when getitem is implemented in tensor\n",
    "        y = Tensor(one_hot_encode(y, q.shape[-1])) #shape (B, C)\n",
    "        loss = -(y * (q+dtype_eps).log()).sum(axis=-1).mean()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "class MeanSquaredError():\n",
    "    def __call__(self, q: Tensor, y) -> Tensor:\n",
    "        '''pred q, shape (B, C), true values y, shape (B, C)'''\n",
    "        loss = ((q - y) ** 2).sum(axis=-1).mean()\n",
    "        return loss\n",
    "\n",
    "class optimiser():\n",
    "    def __init__(self, params: list[Parameter], lr: float=0.005):\n",
    "        self.lr = lr\n",
    "        self.params = params\n",
    "    \n",
    "    @abstractmethod\n",
    "    def step(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        for param in self.params:\n",
    "            param.zero_grad()\n",
    "\n",
    "    def train(self) -> None:\n",
    "        for param in self.params:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def eval(self) -> None:\n",
    "        for param in self.params:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    \n",
    "class SGD(optimiser):\n",
    "    \n",
    "    def step(self) -> None:\n",
    "        for param in self.params:\n",
    "            if not param.requires_grad:\n",
    "                continue \n",
    "            param.data += -self.lr * param.grad\n",
    "\n",
    "class Adam(optimiser):\n",
    "    def __init__(self, params: list[Parameter], lr: float=0.005, \n",
    "                 betas: Tuple[float, float]=(0.9, 0.999), eps: float=1e-8):\n",
    "        super().__init__(params, lr)\n",
    "        self.b1 , self.b2 = betas\n",
    "        self.eps = eps\n",
    "        self.time_step = 0\n",
    "        self.m = [np.zeros_like(param.data, dtype=DTYPE) for param in params]\n",
    "        self.v = [np.zeros_like(param.data, dtype=DTYPE) for param in params]\n",
    "    \n",
    "    def step(self) -> None:\n",
    "        self.time_step += 1\n",
    "        for i, p in enumerate(self.params):\n",
    "            if not p.requires_grad:\n",
    "                continue \n",
    "\n",
    "            g = p.grad\n",
    "            self.m[i] = self.b1*self.m[i] + (1-self.b1)*g\n",
    "            self.v[i] = self.b2*self.v[i] + (1-self.b2)*(g**2)\n",
    "            m_hat = self.m[i]/(1-self.b1**self.time_step)\n",
    "            v_hat = self.v[i]/(1-self.b2**self.time_step)\n",
    "\n",
    "            p.data += -self.lr * m_hat / (v_hat ** 0.5 + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9929b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, input_data, true_data, batch_size, shuffle=False, rng: np.random.Generator=RNG):\n",
    "        assert input_data.shape[0] == true_data.shape[0], 'must have the same number of inputs and true outputs'\n",
    "        self.X = input_data\n",
    "        self.y = true_data\n",
    "        self.N = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.rng = rng\n",
    "\n",
    "    def __iter__(self):\n",
    "        X, y = self.X, self.y\n",
    "        if self.shuffle:\n",
    "            permutation = self.rng.permutation(X.shape[0])\n",
    "            X = X[permutation]\n",
    "            y = y[permutation]\n",
    "        splits = np.arange(self.N, X.shape[0], self.N)\n",
    "        X = np.split(X, splits, axis=0)\n",
    "        X = [Tensor(x, requires_grad=False) for x in X]\n",
    "        y = np.split(y, splits, axis=0)\n",
    "        return zip(X, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        # samples/batch size rounded up\n",
    "        return ceil(self.X.shape[0]/self.N)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6539cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request, numpy as np\n",
    "# import os\n",
    "\n",
    "# os.makedirs('datasets')\n",
    "\n",
    "# url = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\"\n",
    "local_path = r\"datasets/mnist.npz\"\n",
    "\n",
    "# urllib.request.urlretrieve(url, local_path)   # â‡¦ makes a real file\n",
    "data = np.load(local_path)\n",
    "\n",
    "# im = X_train[0:3]\n",
    "# print(type(im))\n",
    "# plt.imshow(im, cmap='grey')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "031abe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = data[\"x_train\"][0:12].reshape((-1,784)) / 255, data[\"y_train\"][0:12]\n",
    "# print(y_train.shape)\n",
    "# train_loader = DataLoader(X_train, y_train, 4, shuffle=True)\n",
    "# for X, y in train_loader:\n",
    "#     print(y)\n",
    "#     im = X[0].reshape((28,28))\n",
    "#     print(type(im))\n",
    "#     plt.imshow(im, cmap='grey')\n",
    "#     plt.show()\n",
    "#     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "725b5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(array, num_c):\n",
    "    one_hot = np.zeros(shape=(array.size, num_c))\n",
    "    for idx, i in enumerate(array):\n",
    "        one_hot[idx, i] = 1\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58fc738e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[parameter shape: (784, 100), size: 78400,\n",
       " parameter shape: (100,), size: 100,\n",
       " parameter shape: (100, 200), size: 20000,\n",
       " parameter shape: (200,), size: 200,\n",
       " parameter shape: (200, 10), size: 2000,\n",
       " parameter shape: (10,), size: 10]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = Sequential([Affine(784, 100), Relu(), Affine(100, 200), Relu(), Affine(200, 10), SoftMax()])\n",
    "nn.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0202b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAverageMeter():\n",
    "    def __init__(self):\n",
    "        self._metrics = {}\n",
    "        self._counts = {}\n",
    "    \n",
    "    def update(self, metric, mean, n=1):\n",
    "        if metric in self._metrics.keys():\n",
    "            k = self._counts[metric]\n",
    "            self._metrics[metric] += n*(mean - self._metrics[metric])/(k+n)\n",
    "            self._counts[metric] += n\n",
    "        else:\n",
    "            self._metrics[metric] = mean\n",
    "            self._counts[metric] = n\n",
    "    \n",
    "    def get_metric(self, metric):\n",
    "        if metric in self._metrics:\n",
    "            return  self._metrics[metric]\n",
    "        raise KeyError(f'{metric} not found')\n",
    "    \n",
    "    def dump_metrics(self):\n",
    "        return self._metrics\n",
    "\n",
    "    def reset(self, metric=None):\n",
    "        if metric is None:\n",
    "            self._metrics = {}\n",
    "            self._counts = {}\n",
    "        else:\n",
    "            del self._metrics[metric]\n",
    "            del self._counts[metric]\n",
    "\n",
    "    def get_log_str(self, metrics=None):\n",
    "        log_str = ''\n",
    "        metrics = self._metrics.keys() if metrics is None else metrics\n",
    "        for metric in metrics:\n",
    "            if metric not in self._metrics:\n",
    "                continue\n",
    "            log_str += f'{metric} : {self._metrics[metric]:.4f} '\n",
    "        return log_str\n",
    "\n",
    "    def __getitem__(self, key):  \n",
    "        return self.get_metric(key)\n",
    "    \n",
    "    def __contains__(self, key): \n",
    "        return key in self._metrics\n",
    "    \n",
    "    def __iter__(self):          \n",
    "        return iter(self._metrics)\n",
    "    \n",
    "    def items(self):            \n",
    "        return self._metrics.items()\n",
    "    \n",
    "    def __len__(self):           \n",
    "        return len(self._metrics)\n",
    "    \n",
    "    def __repr__(self):          \n",
    "        return f\"MultiAverageMeter({self._metrics})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bc98108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wandb_run(wandb_config:dict, api_key:str|None=None):\n",
    "    if api_key is None:\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "    assert api_key is not None, 'api key required'\n",
    "\n",
    "    wandb.login(key=api_key)\n",
    "    return wandb.init(**wandb_config)\n",
    "\n",
    "\n",
    "class WandBLogger():\n",
    "    def __init__(self, meter:MultiAverageMeter, wandb_config:dict, api_key:str|None=None):\n",
    "        self._meter = meter\n",
    "        self._wandb_run = get_wandb_run(wandb_config, api_key)\n",
    "        self._mode = 'train'\n",
    "\n",
    "    def eval(self):\n",
    "        self._mode = 'eval'\n",
    "\n",
    "    def train(self):\n",
    "        self._mode = 'train'\n",
    "\n",
    "    def test(self):\n",
    "        self._mode = 'test'\n",
    "\n",
    "    def log_epoch(self, epoch):\n",
    "        metrics = {}\n",
    "        for name, val in self._meter.items():\n",
    "            metrics[name + f'/{self._mode}'] = val\n",
    "        metrics = metrics | self.get_system_metrics()\n",
    "        self._wandb_run.log(metrics, step=epoch)\n",
    "\n",
    "    def get_system_metrics(self):\n",
    "        metrics = {\n",
    "            'sys/ram_gb' : proc.memory_info().rss / 1_073_741_824\n",
    "        }\n",
    "        return metrics\n",
    "    \n",
    "    def finish(self):\n",
    "        self._wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "814187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_config = {'project': 'torch from scratch testing',\n",
    "                'name': 'dropout_tests',\n",
    "                'config': {'optimiser':'adam', 'lr':0.05},\n",
    "                'group': 'mnist tests',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2aa3f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TODO:\n",
    " - early stopping\n",
    " - overfit batch\n",
    " '''\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(\n",
    "            self, \n",
    "            model: Module, \n",
    "            optimiser: optimiser, \n",
    "            loss_fn: Loss_Fn, \n",
    "            train_loader: DataLoader, \n",
    "            validation_loader: DataLoader, \n",
    "            test_loader: DataLoader, \n",
    "            logger, \n",
    "            wandb_logger: WandBLogger | None = None):\n",
    "        \n",
    "        self.model = model\n",
    "        self.optimiser = optimiser\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_loader = train_loader\n",
    "        self.validation_loader = validation_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.epoch = 1\n",
    "        self.logger = logger\n",
    "        self.wandb_logger = wandb_logger\n",
    "        self.meter = MultiAverageMeter()\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "\n",
    "        for X, y in self.train_loader:\n",
    "            self.optimiser.zero_grad()\n",
    "            output = self.model(X)\n",
    "            loss = self.loss_fn(output, y)\n",
    "            loss.backward()\n",
    "            self.optimiser.step()\n",
    "\n",
    "        return self.meter.get_log_str()\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "\n",
    "        for X, y in self.validation_loader:\n",
    "            self.optimiser.zero_grad()\n",
    "            output = self.model(X)\n",
    "            loss = self.loss_fn(output, y)\n",
    "        \n",
    "        return self.meter.get_log_str()\n",
    "    \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "\n",
    "        for X, y in self.validation_loader:\n",
    "            self.optimiser.zero_grad()\n",
    "            output = self.model(X)\n",
    "            loss = self.loss_fn(output, y)\n",
    "\n",
    "    def train(self, epochs: int):\n",
    "        for t in range(epochs):\n",
    "            print(f'epoch: {t}')\n",
    "            if self.wandb_logger is not None: self.wandb_logger.train()\n",
    "            self.meter.reset()\n",
    "            \n",
    "            log = self.train_epoch()\n",
    "            print('train: ' + log)\n",
    "            if self.wandb_logger is not None: self.wandb_logger.log_epoch(t)\n",
    "\n",
    "\n",
    "            if self.wandb_logger is not None: self.wandb_logger.eval()\n",
    "            self.meter.reset()\n",
    "            log = self.validate()\n",
    "            print('test: ' + log)\n",
    "            if self.wandb_logger is not None: self.wandb_logger.log_epoch(t)\n",
    "    \n",
    "    def log_metrics(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bff5d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_step(meter:MultiAverageMeter, train, nn, loader, loss_fn, optimiser):\n",
    "    start = time.time()\n",
    "    if train:\n",
    "        nn.train()\n",
    "    else:\n",
    "        nn.eval()\n",
    "\n",
    "    for X, y in loader:\n",
    "\n",
    "        nn.zero_grad()\n",
    "        out = nn(X)\n",
    "        loss = loss_fn(out, y)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "        \n",
    "        preds = np.argmax(out.item(), axis=-1)\n",
    "        acc = np.sum(preds == y) / preds.size \n",
    "        \n",
    "        meter.update('CE', loss.item(), y.shape[0])\n",
    "        meter.update('accuracy', acc, y.shape[0])\n",
    "    end = time.time()\n",
    "    meter.update('speed/epoch_sec', end - start)\n",
    "    meter.update('speed/samples_per_sec', len(loader) / (end - start))\n",
    "    return meter.get_log_str()\n",
    "\n",
    "def train_nn(epochs, p=0.0):\n",
    "\n",
    "    meter = MultiAverageMeter()\n",
    "    wandb_logger = WandBLogger(meter, wandb_config)\n",
    "\n",
    "    X_train, y_train = data[\"x_train\"].reshape((-1,784)) / 255, data[\"y_train\"]\n",
    "    X_test, y_test = data[\"x_test\"].reshape((-1,784)) / 255, data[\"y_test\"]\n",
    "\n",
    "    train_loader = DataLoader(X_train, y_train, 256, shuffle=True)\n",
    "    test_loader = DataLoader(X_test, y_test, 256, shuffle=False)\n",
    "\n",
    "    nn = Sequential([DropOut(p), Affine(784, 200), DropOut(p), Relu(), Affine(200, 100), Relu(), Affine(100, 50), Relu(), Affine(50, 10), SoftMax()])\n",
    "    # nn = Sequential([Affine(784, 100), Relu(), Affine(100, 200), Relu(), Affine(200, 10), SoftMax()])\n",
    "    loss_fn = CrossEntropy()\n",
    "    optimiser = Adam(nn.params)\n",
    "    # optimiser = SGD(nn.params, lr=0.05)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f'epoch: {t}')\n",
    "        wandb_logger.train()\n",
    "        meter.reset()\n",
    "        log = train_test_step(meter, True, nn, train_loader, loss_fn, optimiser)\n",
    "        print('train: ' + log)\n",
    "        wandb_logger.log_epoch(t)\n",
    "\n",
    "        wandb_logger.eval()\n",
    "        meter.reset()\n",
    "        log = train_test_step(meter, False, nn, test_loader, loss_fn, optimiser)\n",
    "        print('test: ' + log)\n",
    "        wandb_logger.log_epoch(t)\n",
    "\n",
    "    wandb_logger.finish()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2335e541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_tests</strong> at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/wu0fruc8' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/wu0fruc8</a><br> View project at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250728_235659-wu0fruc8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nik/deep_learning_projects/dqn_from_scratch/wandb/run-20250728_235738-gcowf1hf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/gcowf1hf' target=\"_blank\">dropout_tests</a></strong> to <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/gcowf1hf' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/gcowf1hf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: CE : 0.2515 accuracy : 0.9229 speed/epoch_sec : 1.1488 speed/samples_per_sec : 204.5629 \n",
      "test: CE : 0.1167 accuracy : 0.9630 speed/epoch_sec : 0.0506 speed/samples_per_sec : 790.2152 \n",
      "epoch: 1\n",
      "train: CE : 0.1022 accuracy : 0.9692 speed/epoch_sec : 1.1814 speed/samples_per_sec : 198.9110 \n",
      "test: CE : 0.1147 accuracy : 0.9672 speed/epoch_sec : 0.0303 speed/samples_per_sec : 1319.0880 \n",
      "epoch: 2\n",
      "train: CE : 0.0793 accuracy : 0.9757 speed/epoch_sec : 1.4261 speed/samples_per_sec : 164.7879 \n",
      "test: CE : 0.0944 accuracy : 0.9710 speed/epoch_sec : 0.0382 speed/samples_per_sec : 1046.7638 \n",
      "epoch: 3\n",
      "train: CE : 0.0593 accuracy : 0.9810 speed/epoch_sec : 1.4965 speed/samples_per_sec : 157.0364 \n",
      "test: CE : 0.0901 accuracy : 0.9748 speed/epoch_sec : 0.0319 speed/samples_per_sec : 1253.2469 \n",
      "epoch: 4\n",
      "train: CE : 0.0465 accuracy : 0.9848 speed/epoch_sec : 1.4309 speed/samples_per_sec : 164.2300 \n",
      "test: CE : 0.1061 accuracy : 0.9730 speed/epoch_sec : 0.0334 speed/samples_per_sec : 1197.9533 \n",
      "epoch: 5\n",
      "train: CE : 0.0436 accuracy : 0.9861 speed/epoch_sec : 1.5598 speed/samples_per_sec : 150.6621 \n",
      "test: CE : 0.0836 accuracy : 0.9754 speed/epoch_sec : 0.0355 speed/samples_per_sec : 1128.2669 \n",
      "epoch: 6\n",
      "train: CE : 0.0359 accuracy : 0.9882 speed/epoch_sec : 1.3871 speed/samples_per_sec : 169.4177 \n",
      "test: CE : 0.0855 accuracy : 0.9780 speed/epoch_sec : 0.0305 speed/samples_per_sec : 1311.1092 \n",
      "epoch: 7\n",
      "train: CE : 0.0342 accuracy : 0.9889 speed/epoch_sec : 1.2151 speed/samples_per_sec : 193.4037 \n",
      "test: CE : 0.0886 accuracy : 0.9753 speed/epoch_sec : 0.0274 speed/samples_per_sec : 1459.2944 \n",
      "epoch: 8\n",
      "train: CE : 0.0347 accuracy : 0.9889 speed/epoch_sec : 1.4819 speed/samples_per_sec : 158.5820 \n",
      "test: CE : 0.0957 accuracy : 0.9745 speed/epoch_sec : 0.0310 speed/samples_per_sec : 1288.9488 \n",
      "epoch: 9\n",
      "train: CE : 0.0265 accuracy : 0.9914 speed/epoch_sec : 1.4010 speed/samples_per_sec : 167.7392 \n",
      "test: CE : 0.1097 accuracy : 0.9750 speed/epoch_sec : 0.0332 speed/samples_per_sec : 1203.4788 \n",
      "epoch: 10\n",
      "train: CE : 0.0238 accuracy : 0.9922 speed/epoch_sec : 1.2801 speed/samples_per_sec : 183.5760 \n",
      "test: CE : 0.1074 accuracy : 0.9752 speed/epoch_sec : 0.0291 speed/samples_per_sec : 1375.3395 \n",
      "epoch: 11\n",
      "train: CE : 0.0257 accuracy : 0.9920 speed/epoch_sec : 1.3719 speed/samples_per_sec : 171.2958 \n",
      "test: CE : 0.0927 accuracy : 0.9773 speed/epoch_sec : 0.0287 speed/samples_per_sec : 1396.0770 \n",
      "epoch: 12\n",
      "train: CE : 0.0242 accuracy : 0.9921 speed/epoch_sec : 1.2252 speed/samples_per_sec : 191.8063 \n",
      "test: CE : 0.1071 accuracy : 0.9754 speed/epoch_sec : 0.0343 speed/samples_per_sec : 1165.1735 \n",
      "epoch: 13\n",
      "train: CE : 0.0247 accuracy : 0.9924 speed/epoch_sec : 1.4586 speed/samples_per_sec : 161.1146 \n",
      "test: CE : 0.0932 accuracy : 0.9781 speed/epoch_sec : 0.0295 speed/samples_per_sec : 1355.3513 \n",
      "epoch: 14\n",
      "train: CE : 0.0202 accuracy : 0.9938 speed/epoch_sec : 1.6499 speed/samples_per_sec : 142.4299 \n",
      "test: CE : 0.1314 accuracy : 0.9725 speed/epoch_sec : 0.0457 speed/samples_per_sec : 875.1762 \n",
      "epoch: 15\n",
      "train: CE : 0.0221 accuracy : 0.9932 speed/epoch_sec : 1.4536 speed/samples_per_sec : 161.6727 \n",
      "test: CE : 0.1191 accuracy : 0.9761 speed/epoch_sec : 0.0317 speed/samples_per_sec : 1261.8528 \n",
      "epoch: 16\n",
      "train: CE : 0.0175 accuracy : 0.9946 speed/epoch_sec : 1.2519 speed/samples_per_sec : 187.7163 \n",
      "test: CE : 0.1070 accuracy : 0.9774 speed/epoch_sec : 0.0286 speed/samples_per_sec : 1400.8680 \n",
      "epoch: 17\n",
      "train: CE : 0.0196 accuracy : 0.9938 speed/epoch_sec : 1.1434 speed/samples_per_sec : 205.5250 \n",
      "test: CE : 0.1091 accuracy : 0.9771 speed/epoch_sec : 0.0271 speed/samples_per_sec : 1474.9590 \n",
      "epoch: 18\n",
      "train: CE : 0.0210 accuracy : 0.9936 speed/epoch_sec : 1.1718 speed/samples_per_sec : 200.5456 \n",
      "test: CE : 0.1001 accuracy : 0.9781 speed/epoch_sec : 0.0291 speed/samples_per_sec : 1376.5469 \n",
      "epoch: 19\n",
      "train: CE : 0.0183 accuracy : 0.9943 speed/epoch_sec : 1.2617 speed/samples_per_sec : 186.2632 \n",
      "test: CE : 0.1276 accuracy : 0.9764 speed/epoch_sec : 0.0572 speed/samples_per_sec : 699.0128 \n",
      "epoch: 20\n",
      "train: CE : 0.0168 accuracy : 0.9948 speed/epoch_sec : 1.2921 speed/samples_per_sec : 181.8782 \n",
      "test: CE : 0.1118 accuracy : 0.9792 speed/epoch_sec : 0.0278 speed/samples_per_sec : 1438.3512 \n",
      "epoch: 21\n",
      "train: CE : 0.0172 accuracy : 0.9947 speed/epoch_sec : 1.1465 speed/samples_per_sec : 204.9640 \n",
      "test: CE : 0.1010 accuracy : 0.9786 speed/epoch_sec : 0.0278 speed/samples_per_sec : 1436.4547 \n",
      "epoch: 22\n",
      "train: CE : 0.0117 accuracy : 0.9965 speed/epoch_sec : 1.1284 speed/samples_per_sec : 208.2591 \n",
      "test: CE : 0.1123 accuracy : 0.9794 speed/epoch_sec : 0.0273 speed/samples_per_sec : 1463.2016 \n",
      "epoch: 23\n",
      "train: CE : 0.0152 accuracy : 0.9954 speed/epoch_sec : 1.1990 speed/samples_per_sec : 195.9984 \n",
      "test: CE : 0.1261 accuracy : 0.9757 speed/epoch_sec : 0.0418 speed/samples_per_sec : 956.8118 \n",
      "epoch: 24\n",
      "train: CE : 0.0163 accuracy : 0.9951 speed/epoch_sec : 1.2373 speed/samples_per_sec : 189.9345 \n",
      "test: CE : 0.1008 accuracy : 0.9799 speed/epoch_sec : 0.0282 speed/samples_per_sec : 1416.2888 \n",
      "epoch: 25\n",
      "train: CE : 0.0151 accuracy : 0.9957 speed/epoch_sec : 1.1779 speed/samples_per_sec : 199.5139 \n",
      "test: CE : 0.1234 accuracy : 0.9757 speed/epoch_sec : 0.0344 speed/samples_per_sec : 1164.2194 \n",
      "epoch: 26\n",
      "train: CE : 0.0168 accuracy : 0.9954 speed/epoch_sec : 1.2097 speed/samples_per_sec : 194.2563 \n",
      "test: CE : 0.1218 accuracy : 0.9777 speed/epoch_sec : 0.0305 speed/samples_per_sec : 1311.8987 \n",
      "epoch: 27\n",
      "train: CE : 0.0129 accuracy : 0.9961 speed/epoch_sec : 1.1875 speed/samples_per_sec : 197.9006 \n",
      "test: CE : 0.1120 accuracy : 0.9799 speed/epoch_sec : 0.0305 speed/samples_per_sec : 1313.3467 \n",
      "epoch: 28\n",
      "train: CE : 0.0120 accuracy : 0.9966 speed/epoch_sec : 1.2064 speed/samples_per_sec : 194.7984 \n",
      "test: CE : 0.1149 accuracy : 0.9785 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1410.9765 \n",
      "epoch: 29\n",
      "train: CE : 0.0093 accuracy : 0.9974 speed/epoch_sec : 1.3172 speed/samples_per_sec : 178.4047 \n",
      "test: CE : 0.1303 accuracy : 0.9777 speed/epoch_sec : 0.0278 speed/samples_per_sec : 1438.0183 \n",
      "epoch: 30\n",
      "train: CE : 0.0120 accuracy : 0.9967 speed/epoch_sec : 1.3309 speed/samples_per_sec : 176.5665 \n",
      "test: CE : 0.1180 accuracy : 0.9788 speed/epoch_sec : 0.0524 speed/samples_per_sec : 763.6282 \n",
      "epoch: 31\n",
      "train: CE : 0.0145 accuracy : 0.9956 speed/epoch_sec : 1.2045 speed/samples_per_sec : 195.0962 \n",
      "test: CE : 0.1248 accuracy : 0.9792 speed/epoch_sec : 0.0281 speed/samples_per_sec : 1424.8287 \n",
      "epoch: 32\n",
      "train: CE : 0.0144 accuracy : 0.9964 speed/epoch_sec : 1.6609 speed/samples_per_sec : 141.4931 \n",
      "test: CE : 0.1054 accuracy : 0.9806 speed/epoch_sec : 0.0285 speed/samples_per_sec : 1403.8924 \n",
      "epoch: 33\n",
      "train: CE : 0.0118 accuracy : 0.9966 speed/epoch_sec : 1.4966 speed/samples_per_sec : 157.0236 \n",
      "test: CE : 0.1440 accuracy : 0.9766 speed/epoch_sec : 0.0328 speed/samples_per_sec : 1218.3447 \n",
      "epoch: 34\n",
      "train: CE : 0.0151 accuracy : 0.9960 speed/epoch_sec : 1.5140 speed/samples_per_sec : 155.2164 \n",
      "test: CE : 0.1380 accuracy : 0.9791 speed/epoch_sec : 0.0276 speed/samples_per_sec : 1447.3723 \n",
      "epoch: 35\n",
      "train: CE : 0.0111 accuracy : 0.9971 speed/epoch_sec : 1.1871 speed/samples_per_sec : 197.9690 \n",
      "test: CE : 0.1279 accuracy : 0.9794 speed/epoch_sec : 0.0309 speed/samples_per_sec : 1292.9221 \n",
      "epoch: 36\n",
      "train: CE : 0.0129 accuracy : 0.9967 speed/epoch_sec : 1.3238 speed/samples_per_sec : 177.5232 \n",
      "test: CE : 0.1297 accuracy : 0.9782 speed/epoch_sec : 0.0340 speed/samples_per_sec : 1177.1255 \n",
      "epoch: 37\n",
      "train: CE : 0.0131 accuracy : 0.9964 speed/epoch_sec : 1.3564 speed/samples_per_sec : 173.2542 \n",
      "test: CE : 0.1264 accuracy : 0.9787 speed/epoch_sec : 0.0311 speed/samples_per_sec : 1285.9356 \n",
      "epoch: 38\n",
      "train: CE : 0.0140 accuracy : 0.9961 speed/epoch_sec : 1.2968 speed/samples_per_sec : 181.2208 \n",
      "test: CE : 0.1617 accuracy : 0.9761 speed/epoch_sec : 0.0275 speed/samples_per_sec : 1452.9880 \n",
      "epoch: 39\n",
      "train: CE : 0.0131 accuracy : 0.9965 speed/epoch_sec : 1.1125 speed/samples_per_sec : 211.2266 \n",
      "test: CE : 0.1190 accuracy : 0.9795 speed/epoch_sec : 0.0274 speed/samples_per_sec : 1458.6220 \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>â–„â–„â–‚â–‚â–ƒâ–â–â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–„â–ƒâ–ƒâ–‚â–…â–„â–ƒâ–„â–…â–ƒâ–…â–„â–„â–„â–…â–„â–…â–ƒâ–†â–†â–…â–…â–…â–ˆâ–„</td></tr><tr><td>CE/train</td><td>â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>accuracy/eval</td><td>â–â–ƒâ–„â–†â–…â–†â–‡â–†â–†â–†â–†â–‡â–†â–‡â–…â–†â–‡â–‡â–‡â–†â–‡â–‡â–ˆâ–†â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–ˆâ–‡â–‡â–†â–ˆ</td></tr><tr><td>accuracy/train</td><td>â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>speed/epoch_sec/eval</td><td>â–†â–‚â–„â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–â–ƒâ–‚â–…â–‚â–â–â–â–ˆâ–â–â–â–„â–â–ƒâ–‚â–‚â–â–â–‡â–â–â–‚â–â–‚â–ƒâ–‚â–â–</td></tr><tr><td>speed/epoch_sec/train</td><td>â–â–‚â–…â–†â–…â–‡â–…â–‚â–†â–…â–ƒâ–„â–‚â–…â–ˆâ–…â–ƒâ–â–‚â–ƒâ–ƒâ–â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–„â–„â–‚â–ˆâ–†â–†â–‚â–„â–„â–ƒâ–</td></tr><tr><td>speed/samples_per_sec/eval</td><td>â–‚â–‡â–„â–†â–†â–…â–‡â–ˆâ–†â–†â–‡â–‡â–…â–‡â–ƒâ–†â–‡â–ˆâ–‡â–â–ˆâ–ˆâ–ˆâ–ƒâ–‡â–…â–‡â–‡â–‡â–ˆâ–‚â–ˆâ–‡â–†â–ˆâ–†â–…â–†â–ˆâ–ˆ</td></tr><tr><td>speed/samples_per_sec/train</td><td>â–‡â–‡â–ƒâ–ƒâ–ƒâ–‚â–„â–†â–ƒâ–„â–…â–„â–†â–ƒâ–â–ƒâ–†â–‡â–‡â–…â–…â–‡â–ˆâ–†â–†â–‡â–†â–‡â–†â–…â–…â–†â–â–ƒâ–‚â–‡â–…â–„â–…â–ˆ</td></tr><tr><td>sys/ram_gb</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>0.11896</td></tr><tr><td>CE/train</td><td>0.01309</td></tr><tr><td>accuracy/eval</td><td>0.9795</td></tr><tr><td>accuracy/train</td><td>0.99647</td></tr><tr><td>speed/epoch_sec/eval</td><td>0.02742</td></tr><tr><td>speed/epoch_sec/train</td><td>1.11255</td></tr><tr><td>speed/samples_per_sec/eval</td><td>1458.62199</td></tr><tr><td>speed/samples_per_sec/train</td><td>211.22659</td></tr><tr><td>sys/ram_gb</td><td>1.79058</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_tests</strong> at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/gcowf1hf' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/gcowf1hf</a><br> View project at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250728_235738-gcowf1hf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nik/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nik/deep_learning_projects/dqn_from_scratch/wandb/run-20250728_235835-2jvlyt4a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/2jvlyt4a' target=\"_blank\">dropout_tests</a></strong> to <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/2jvlyt4a' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/2jvlyt4a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: CE : 0.2632 accuracy : 0.9183 speed/epoch_sec : 1.1836 speed/samples_per_sec : 198.5445 \n",
      "test: CE : 0.1194 accuracy : 0.9624 speed/epoch_sec : 0.0299 speed/samples_per_sec : 1339.7122 \n",
      "epoch: 1\n",
      "train: CE : 0.1131 accuracy : 0.9645 speed/epoch_sec : 1.1518 speed/samples_per_sec : 204.0339 \n",
      "test: CE : 0.1140 accuracy : 0.9651 speed/epoch_sec : 0.0267 speed/samples_per_sec : 1497.3507 \n",
      "epoch: 2\n",
      "train: CE : 0.0871 accuracy : 0.9725 speed/epoch_sec : 1.2111 speed/samples_per_sec : 194.0449 \n",
      "test: CE : 0.0850 accuracy : 0.9733 speed/epoch_sec : 0.0278 speed/samples_per_sec : 1439.8201 \n",
      "epoch: 3\n",
      "train: CE : 0.0760 accuracy : 0.9765 speed/epoch_sec : 1.3593 speed/samples_per_sec : 172.8878 \n",
      "test: CE : 0.1061 accuracy : 0.9685 speed/epoch_sec : 0.0299 speed/samples_per_sec : 1337.0430 \n",
      "epoch: 4\n",
      "train: CE : 0.0605 accuracy : 0.9809 speed/epoch_sec : 1.1408 speed/samples_per_sec : 205.9868 \n",
      "test: CE : 0.0827 accuracy : 0.9769 speed/epoch_sec : 0.0308 speed/samples_per_sec : 1299.1796 \n",
      "epoch: 5\n",
      "train: CE : 0.0503 accuracy : 0.9835 speed/epoch_sec : 1.2522 speed/samples_per_sec : 187.6673 \n",
      "test: CE : 0.0888 accuracy : 0.9760 speed/epoch_sec : 0.0463 speed/samples_per_sec : 863.8342 \n",
      "epoch: 6\n",
      "train: CE : 0.0507 accuracy : 0.9840 speed/epoch_sec : 1.1659 speed/samples_per_sec : 201.5579 \n",
      "test: CE : 0.0788 accuracy : 0.9773 speed/epoch_sec : 0.0284 speed/samples_per_sec : 1409.9093 \n",
      "epoch: 7\n",
      "train: CE : 0.0490 accuracy : 0.9844 speed/epoch_sec : 1.2170 speed/samples_per_sec : 193.1048 \n",
      "test: CE : 0.0784 accuracy : 0.9794 speed/epoch_sec : 0.0269 speed/samples_per_sec : 1484.4861 \n",
      "epoch: 8\n",
      "train: CE : 0.0456 accuracy : 0.9851 speed/epoch_sec : 1.1050 speed/samples_per_sec : 212.6791 \n",
      "test: CE : 0.0834 accuracy : 0.9773 speed/epoch_sec : 0.0282 speed/samples_per_sec : 1417.3417 \n",
      "epoch: 9\n",
      "train: CE : 0.0398 accuracy : 0.9874 speed/epoch_sec : 1.1857 speed/samples_per_sec : 198.1872 \n",
      "test: CE : 0.0746 accuracy : 0.9790 speed/epoch_sec : 0.0281 speed/samples_per_sec : 1424.7682 \n",
      "epoch: 10\n",
      "train: CE : 0.0380 accuracy : 0.9874 speed/epoch_sec : 1.0767 speed/samples_per_sec : 218.2696 \n",
      "test: CE : 0.0759 accuracy : 0.9805 speed/epoch_sec : 0.0273 speed/samples_per_sec : 1463.3931 \n",
      "epoch: 11\n",
      "train: CE : 0.0350 accuracy : 0.9891 speed/epoch_sec : 1.0740 speed/samples_per_sec : 218.8016 \n",
      "test: CE : 0.0717 accuracy : 0.9808 speed/epoch_sec : 0.0267 speed/samples_per_sec : 1495.6288 \n",
      "epoch: 12\n",
      "train: CE : 0.0374 accuracy : 0.9885 speed/epoch_sec : 1.3954 speed/samples_per_sec : 168.4098 \n",
      "test: CE : 0.0930 accuracy : 0.9771 speed/epoch_sec : 0.0289 speed/samples_per_sec : 1384.3958 \n",
      "epoch: 13\n",
      "train: CE : 0.0324 accuracy : 0.9896 speed/epoch_sec : 1.2028 speed/samples_per_sec : 195.3833 \n",
      "test: CE : 0.0837 accuracy : 0.9803 speed/epoch_sec : 0.0272 speed/samples_per_sec : 1471.1436 \n",
      "epoch: 14\n",
      "train: CE : 0.0308 accuracy : 0.9901 speed/epoch_sec : 1.1125 speed/samples_per_sec : 211.2342 \n",
      "test: CE : 0.0831 accuracy : 0.9804 speed/epoch_sec : 0.0287 speed/samples_per_sec : 1395.0091 \n",
      "epoch: 15\n",
      "train: CE : 0.0317 accuracy : 0.9899 speed/epoch_sec : 1.1179 speed/samples_per_sec : 210.2153 \n",
      "test: CE : 0.0907 accuracy : 0.9796 speed/epoch_sec : 0.0290 speed/samples_per_sec : 1381.4889 \n",
      "epoch: 16\n",
      "train: CE : 0.0278 accuracy : 0.9911 speed/epoch_sec : 1.2293 speed/samples_per_sec : 191.1618 \n",
      "test: CE : 0.0813 accuracy : 0.9813 speed/epoch_sec : 0.0383 speed/samples_per_sec : 1044.5935 \n",
      "epoch: 17\n",
      "train: CE : 0.0284 accuracy : 0.9912 speed/epoch_sec : 1.1569 speed/samples_per_sec : 203.1249 \n",
      "test: CE : 0.0847 accuracy : 0.9793 speed/epoch_sec : 0.0314 speed/samples_per_sec : 1275.2714 \n",
      "epoch: 18\n",
      "train: CE : 0.0232 accuracy : 0.9924 speed/epoch_sec : 1.1841 speed/samples_per_sec : 198.4584 \n",
      "test: CE : 0.0874 accuracy : 0.9794 speed/epoch_sec : 0.0299 speed/samples_per_sec : 1336.4572 \n",
      "epoch: 19\n",
      "train: CE : 0.0287 accuracy : 0.9913 speed/epoch_sec : 1.8364 speed/samples_per_sec : 127.9644 \n",
      "test: CE : 0.0800 accuracy : 0.9812 speed/epoch_sec : 0.0556 speed/samples_per_sec : 718.7781 \n",
      "epoch: 20\n",
      "train: CE : 0.0274 accuracy : 0.9913 speed/epoch_sec : 1.8803 speed/samples_per_sec : 124.9782 \n",
      "test: CE : 0.0812 accuracy : 0.9799 speed/epoch_sec : 0.0342 speed/samples_per_sec : 1168.4600 \n",
      "epoch: 21\n",
      "train: CE : 0.0220 accuracy : 0.9933 speed/epoch_sec : 1.2094 speed/samples_per_sec : 194.3120 \n",
      "test: CE : 0.0940 accuracy : 0.9802 speed/epoch_sec : 0.0288 speed/samples_per_sec : 1388.3827 \n",
      "epoch: 22\n",
      "train: CE : 0.0230 accuracy : 0.9934 speed/epoch_sec : 1.1577 speed/samples_per_sec : 202.9810 \n",
      "test: CE : 0.1033 accuracy : 0.9784 speed/epoch_sec : 0.0295 speed/samples_per_sec : 1357.0506 \n",
      "epoch: 23\n",
      "train: CE : 0.0250 accuracy : 0.9926 speed/epoch_sec : 1.1279 speed/samples_per_sec : 208.3609 \n",
      "test: CE : 0.0782 accuracy : 0.9820 speed/epoch_sec : 0.0282 speed/samples_per_sec : 1418.9480 \n",
      "epoch: 24\n",
      "train: CE : 0.0207 accuracy : 0.9932 speed/epoch_sec : 1.2317 speed/samples_per_sec : 190.7995 \n",
      "test: CE : 0.0841 accuracy : 0.9817 speed/epoch_sec : 0.0293 speed/samples_per_sec : 1363.8461 \n",
      "epoch: 25\n",
      "train: CE : 0.0239 accuracy : 0.9927 speed/epoch_sec : 1.1567 speed/samples_per_sec : 203.1639 \n",
      "test: CE : 0.0931 accuracy : 0.9808 speed/epoch_sec : 0.0281 speed/samples_per_sec : 1420.9911 \n",
      "epoch: 26\n",
      "train: CE : 0.0240 accuracy : 0.9926 speed/epoch_sec : 1.1425 speed/samples_per_sec : 205.6851 \n",
      "test: CE : 0.0874 accuracy : 0.9806 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1362.2625 \n",
      "epoch: 27\n",
      "train: CE : 0.0214 accuracy : 0.9934 speed/epoch_sec : 1.1752 speed/samples_per_sec : 199.9721 \n",
      "test: CE : 0.0844 accuracy : 0.9799 speed/epoch_sec : 0.0333 speed/samples_per_sec : 1202.5385 \n",
      "epoch: 28\n",
      "train: CE : 0.0204 accuracy : 0.9944 speed/epoch_sec : 1.3599 speed/samples_per_sec : 172.8119 \n",
      "test: CE : 0.0903 accuracy : 0.9813 speed/epoch_sec : 0.0316 speed/samples_per_sec : 1267.7454 \n",
      "epoch: 29\n",
      "train: CE : 0.0190 accuracy : 0.9941 speed/epoch_sec : 1.2050 speed/samples_per_sec : 195.0177 \n",
      "test: CE : 0.0898 accuracy : 0.9797 speed/epoch_sec : 0.0306 speed/samples_per_sec : 1308.7875 \n",
      "epoch: 30\n",
      "train: CE : 0.0168 accuracy : 0.9945 speed/epoch_sec : 1.1898 speed/samples_per_sec : 197.5087 \n",
      "test: CE : 0.0934 accuracy : 0.9798 speed/epoch_sec : 0.0302 speed/samples_per_sec : 1324.1372 \n",
      "epoch: 31\n",
      "train: CE : 0.0201 accuracy : 0.9939 speed/epoch_sec : 1.1607 speed/samples_per_sec : 202.4673 \n",
      "test: CE : 0.1050 accuracy : 0.9803 speed/epoch_sec : 0.0316 speed/samples_per_sec : 1267.1900 \n",
      "epoch: 32\n",
      "train: CE : 0.0207 accuracy : 0.9940 speed/epoch_sec : 1.3053 speed/samples_per_sec : 180.0372 \n",
      "test: CE : 0.1030 accuracy : 0.9778 speed/epoch_sec : 0.0292 speed/samples_per_sec : 1368.7642 \n",
      "epoch: 33\n",
      "train: CE : 0.0229 accuracy : 0.9932 speed/epoch_sec : 1.2471 speed/samples_per_sec : 188.4330 \n",
      "test: CE : 0.1036 accuracy : 0.9788 speed/epoch_sec : 0.0289 speed/samples_per_sec : 1381.9896 \n",
      "epoch: 34\n",
      "train: CE : 0.0190 accuracy : 0.9943 speed/epoch_sec : 1.1234 speed/samples_per_sec : 209.1857 \n",
      "test: CE : 0.0922 accuracy : 0.9818 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1411.1664 \n",
      "epoch: 35\n",
      "train: CE : 0.0141 accuracy : 0.9958 speed/epoch_sec : 1.1149 speed/samples_per_sec : 210.7893 \n",
      "test: CE : 0.0968 accuracy : 0.9826 speed/epoch_sec : 0.0268 speed/samples_per_sec : 1490.4602 \n",
      "epoch: 36\n",
      "train: CE : 0.0158 accuracy : 0.9951 speed/epoch_sec : 1.4361 speed/samples_per_sec : 163.6332 \n",
      "test: CE : 0.0989 accuracy : 0.9817 speed/epoch_sec : 0.0315 speed/samples_per_sec : 1270.1544 \n",
      "epoch: 37\n",
      "train: CE : 0.0182 accuracy : 0.9947 speed/epoch_sec : 1.3277 speed/samples_per_sec : 177.0004 \n",
      "test: CE : 0.1078 accuracy : 0.9791 speed/epoch_sec : 0.0291 speed/samples_per_sec : 1374.8661 \n",
      "epoch: 38\n",
      "train: CE : 0.0175 accuracy : 0.9949 speed/epoch_sec : 1.1794 speed/samples_per_sec : 199.2590 \n",
      "test: CE : 0.1026 accuracy : 0.9799 speed/epoch_sec : 0.0327 speed/samples_per_sec : 1221.5649 \n",
      "epoch: 39\n",
      "train: CE : 0.0218 accuracy : 0.9937 speed/epoch_sec : 1.1410 speed/samples_per_sec : 205.9597 \n",
      "test: CE : 0.1061 accuracy : 0.9806 speed/epoch_sec : 0.0287 speed/samples_per_sec : 1391.8612 \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>â–ˆâ–‡â–ƒâ–†â–ƒâ–„â–‚â–‚â–ƒâ–â–‚â–â–„â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–‚â–„â–†â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–†â–†â–†â–„â–…â–…â–†â–†â–†</td></tr><tr><td>CE/train</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>accuracy/eval</td><td>â–â–‚â–…â–ƒâ–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡</td></tr><tr><td>accuracy/train</td><td>â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>speed/epoch_sec/eval</td><td>â–‚â–â–â–‚â–‚â–†â–â–â–â–â–â–â–‚â–â–â–‚â–„â–‚â–‚â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–</td></tr><tr><td>speed/epoch_sec/train</td><td>â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–â–„â–‚â–â–â–‚â–‚â–‚â–ˆâ–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–â–â–„â–ƒâ–‚â–‚</td></tr><tr><td>speed/samples_per_sec/eval</td><td>â–‡â–ˆâ–‡â–‡â–†â–‚â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–„â–†â–‡â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–†â–‡â–†â–‡</td></tr><tr><td>speed/samples_per_sec/train</td><td>â–†â–‡â–†â–…â–‡â–†â–‡â–†â–ˆâ–†â–ˆâ–ˆâ–„â–†â–‡â–‡â–†â–‡â–†â–â–â–†â–‡â–‡â–†â–‡â–‡â–‡â–…â–†â–†â–‡â–…â–†â–‡â–‡â–„â–…â–‡â–‡</td></tr><tr><td>sys/ram_gb</td><td>â–‡â–‡â–‡â–ˆâ–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>0.10614</td></tr><tr><td>CE/train</td><td>0.02178</td></tr><tr><td>accuracy/eval</td><td>0.9806</td></tr><tr><td>accuracy/train</td><td>0.99372</td></tr><tr><td>speed/epoch_sec/eval</td><td>0.02874</td></tr><tr><td>speed/epoch_sec/train</td><td>1.141</td></tr><tr><td>speed/samples_per_sec/eval</td><td>1391.86116</td></tr><tr><td>speed/samples_per_sec/train</td><td>205.95972</td></tr><tr><td>sys/ram_gb</td><td>1.75604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_tests</strong> at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/2jvlyt4a' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/2jvlyt4a</a><br> View project at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250728_235835-2jvlyt4a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nik/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nik/deep_learning_projects/dqn_from_scratch/wandb/run-20250728_235927-lleol8ne</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/lleol8ne' target=\"_blank\">dropout_tests</a></strong> to <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/lleol8ne' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/lleol8ne</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: CE : 0.2819 accuracy : 0.9127 speed/epoch_sec : 1.0989 speed/samples_per_sec : 213.8437 \n",
      "test: CE : 0.1112 accuracy : 0.9655 speed/epoch_sec : 0.0270 speed/samples_per_sec : 1480.8696 \n",
      "epoch: 1\n",
      "train: CE : 0.1276 accuracy : 0.9606 speed/epoch_sec : 1.1742 speed/samples_per_sec : 200.1358 \n",
      "test: CE : 0.0943 accuracy : 0.9712 speed/epoch_sec : 0.0378 speed/samples_per_sec : 1059.2412 \n",
      "epoch: 2\n",
      "train: CE : 0.1028 accuracy : 0.9673 speed/epoch_sec : 1.3224 speed/samples_per_sec : 177.7126 \n",
      "test: CE : 0.0746 accuracy : 0.9759 speed/epoch_sec : 0.0304 speed/samples_per_sec : 1315.7259 \n",
      "epoch: 3\n",
      "train: CE : 0.0839 accuracy : 0.9737 speed/epoch_sec : 1.3679 speed/samples_per_sec : 171.7916 \n",
      "test: CE : 0.0825 accuracy : 0.9744 speed/epoch_sec : 0.0311 speed/samples_per_sec : 1285.2165 \n",
      "epoch: 4\n",
      "train: CE : 0.0820 accuracy : 0.9739 speed/epoch_sec : 1.1963 speed/samples_per_sec : 196.4465 \n",
      "test: CE : 0.0753 accuracy : 0.9776 speed/epoch_sec : 0.0429 speed/samples_per_sec : 932.9435 \n",
      "epoch: 5\n",
      "train: CE : 0.0660 accuracy : 0.9791 speed/epoch_sec : 1.1600 speed/samples_per_sec : 202.5916 \n",
      "test: CE : 0.0785 accuracy : 0.9773 speed/epoch_sec : 0.0264 speed/samples_per_sec : 1512.4283 \n",
      "epoch: 6\n",
      "train: CE : 0.0635 accuracy : 0.9797 speed/epoch_sec : 1.1212 speed/samples_per_sec : 209.6005 \n",
      "test: CE : 0.0743 accuracy : 0.9779 speed/epoch_sec : 0.0355 speed/samples_per_sec : 1125.6930 \n",
      "epoch: 7\n",
      "train: CE : 0.0584 accuracy : 0.9814 speed/epoch_sec : 1.1340 speed/samples_per_sec : 207.2386 \n",
      "test: CE : 0.0757 accuracy : 0.9788 speed/epoch_sec : 0.0291 speed/samples_per_sec : 1376.1066 \n",
      "epoch: 8\n",
      "train: CE : 0.0564 accuracy : 0.9818 speed/epoch_sec : 1.1544 speed/samples_per_sec : 203.5689 \n",
      "test: CE : 0.0729 accuracy : 0.9780 speed/epoch_sec : 0.0520 speed/samples_per_sec : 768.6732 \n",
      "epoch: 9\n",
      "train: CE : 0.0508 accuracy : 0.9838 speed/epoch_sec : 1.0884 speed/samples_per_sec : 215.9099 \n",
      "test: CE : 0.0812 accuracy : 0.9774 speed/epoch_sec : 0.0353 speed/samples_per_sec : 1132.1881 \n",
      "epoch: 10\n",
      "train: CE : 0.0505 accuracy : 0.9839 speed/epoch_sec : 1.0785 speed/samples_per_sec : 217.9016 \n",
      "test: CE : 0.0812 accuracy : 0.9784 speed/epoch_sec : 0.0292 speed/samples_per_sec : 1368.3511 \n",
      "epoch: 11\n",
      "train: CE : 0.0458 accuracy : 0.9853 speed/epoch_sec : 1.1161 speed/samples_per_sec : 210.5630 \n",
      "test: CE : 0.0769 accuracy : 0.9804 speed/epoch_sec : 0.0328 speed/samples_per_sec : 1218.0440 \n",
      "epoch: 12\n",
      "train: CE : 0.0436 accuracy : 0.9866 speed/epoch_sec : 1.3643 speed/samples_per_sec : 172.2477 \n",
      "test: CE : 0.0687 accuracy : 0.9812 speed/epoch_sec : 0.0275 speed/samples_per_sec : 1456.8235 \n",
      "epoch: 13\n",
      "train: CE : 0.0424 accuracy : 0.9864 speed/epoch_sec : 1.1502 speed/samples_per_sec : 204.3133 \n",
      "test: CE : 0.0752 accuracy : 0.9807 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1362.6387 \n",
      "epoch: 14\n",
      "train: CE : 0.0419 accuracy : 0.9868 speed/epoch_sec : 1.1172 speed/samples_per_sec : 210.3545 \n",
      "test: CE : 0.0651 accuracy : 0.9824 speed/epoch_sec : 0.0272 speed/samples_per_sec : 1472.2668 \n",
      "epoch: 15\n",
      "train: CE : 0.0399 accuracy : 0.9869 speed/epoch_sec : 1.1012 speed/samples_per_sec : 213.4077 \n",
      "test: CE : 0.0755 accuracy : 0.9799 speed/epoch_sec : 0.0266 speed/samples_per_sec : 1501.4109 \n",
      "epoch: 16\n",
      "train: CE : 0.0375 accuracy : 0.9883 speed/epoch_sec : 1.1825 speed/samples_per_sec : 198.7344 \n",
      "test: CE : 0.0801 accuracy : 0.9798 speed/epoch_sec : 0.0266 speed/samples_per_sec : 1505.5607 \n",
      "epoch: 17\n",
      "train: CE : 0.0397 accuracy : 0.9872 speed/epoch_sec : 1.1168 speed/samples_per_sec : 210.4243 \n",
      "test: CE : 0.0907 accuracy : 0.9771 speed/epoch_sec : 0.0263 speed/samples_per_sec : 1523.7470 \n",
      "epoch: 18\n",
      "train: CE : 0.0365 accuracy : 0.9882 speed/epoch_sec : 1.1570 speed/samples_per_sec : 203.1165 \n",
      "test: CE : 0.0822 accuracy : 0.9790 speed/epoch_sec : 0.0413 speed/samples_per_sec : 968.0578 \n",
      "epoch: 19\n",
      "train: CE : 0.0348 accuracy : 0.9887 speed/epoch_sec : 1.1385 speed/samples_per_sec : 206.4091 \n",
      "test: CE : 0.0711 accuracy : 0.9826 speed/epoch_sec : 0.0412 speed/samples_per_sec : 970.3702 \n",
      "epoch: 20\n",
      "train: CE : 0.0358 accuracy : 0.9890 speed/epoch_sec : 1.2782 speed/samples_per_sec : 183.8553 \n",
      "test: CE : 0.0687 accuracy : 0.9838 speed/epoch_sec : 0.0301 speed/samples_per_sec : 1329.7837 \n",
      "epoch: 21\n",
      "train: CE : 0.0347 accuracy : 0.9889 speed/epoch_sec : 1.0652 speed/samples_per_sec : 220.6201 \n",
      "test: CE : 0.0909 accuracy : 0.9795 speed/epoch_sec : 0.0274 speed/samples_per_sec : 1459.9166 \n",
      "epoch: 22\n",
      "train: CE : 0.0364 accuracy : 0.9885 speed/epoch_sec : 1.0953 speed/samples_per_sec : 214.5614 \n",
      "test: CE : 0.0888 accuracy : 0.9802 speed/epoch_sec : 0.0515 speed/samples_per_sec : 776.1121 \n",
      "epoch: 23\n",
      "train: CE : 0.0351 accuracy : 0.9891 speed/epoch_sec : 1.2473 speed/samples_per_sec : 188.4081 \n",
      "test: CE : 0.0776 accuracy : 0.9808 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1358.4570 \n",
      "epoch: 24\n",
      "train: CE : 0.0322 accuracy : 0.9899 speed/epoch_sec : 1.0411 speed/samples_per_sec : 225.7230 \n",
      "test: CE : 0.0777 accuracy : 0.9807 speed/epoch_sec : 0.0257 speed/samples_per_sec : 1553.8200 \n",
      "epoch: 25\n",
      "train: CE : 0.0328 accuracy : 0.9896 speed/epoch_sec : 1.0508 speed/samples_per_sec : 223.6468 \n",
      "test: CE : 0.0741 accuracy : 0.9821 speed/epoch_sec : 0.0264 speed/samples_per_sec : 1515.2148 \n",
      "epoch: 26\n",
      "train: CE : 0.0300 accuracy : 0.9906 speed/epoch_sec : 1.1007 speed/samples_per_sec : 213.4968 \n",
      "test: CE : 0.0916 accuracy : 0.9811 speed/epoch_sec : 0.0264 speed/samples_per_sec : 1513.0148 \n",
      "epoch: 27\n",
      "train: CE : 0.0314 accuracy : 0.9907 speed/epoch_sec : 1.3894 speed/samples_per_sec : 169.1340 \n",
      "test: CE : 0.0848 accuracy : 0.9795 speed/epoch_sec : 0.0315 speed/samples_per_sec : 1268.6177 \n",
      "epoch: 28\n",
      "train: CE : 0.0280 accuracy : 0.9910 speed/epoch_sec : 1.0762 speed/samples_per_sec : 218.3540 \n",
      "test: CE : 0.0728 accuracy : 0.9829 speed/epoch_sec : 0.0271 speed/samples_per_sec : 1476.8286 \n",
      "epoch: 29\n",
      "train: CE : 0.0302 accuracy : 0.9903 speed/epoch_sec : 1.5212 speed/samples_per_sec : 154.4849 \n",
      "test: CE : 0.0799 accuracy : 0.9832 speed/epoch_sec : 0.0286 speed/samples_per_sec : 1399.2090 \n",
      "epoch: 30\n",
      "train: CE : 0.0311 accuracy : 0.9900 speed/epoch_sec : 1.2843 speed/samples_per_sec : 182.9769 \n",
      "test: CE : 0.0721 accuracy : 0.9832 speed/epoch_sec : 0.0319 speed/samples_per_sec : 1253.3311 \n",
      "epoch: 31\n",
      "train: CE : 0.0280 accuracy : 0.9917 speed/epoch_sec : 1.1668 speed/samples_per_sec : 201.4115 \n",
      "test: CE : 0.0656 accuracy : 0.9846 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1413.7706 \n",
      "epoch: 32\n",
      "train: CE : 0.0271 accuracy : 0.9913 speed/epoch_sec : 1.2609 speed/samples_per_sec : 186.3728 \n",
      "test: CE : 0.0798 accuracy : 0.9827 speed/epoch_sec : 0.0766 speed/samples_per_sec : 521.9864 \n",
      "epoch: 33\n",
      "train: CE : 0.0295 accuracy : 0.9909 speed/epoch_sec : 1.3151 speed/samples_per_sec : 178.6881 \n",
      "test: CE : 0.0785 accuracy : 0.9808 speed/epoch_sec : 0.0288 speed/samples_per_sec : 1388.0840 \n",
      "epoch: 34\n",
      "train: CE : 0.0290 accuracy : 0.9913 speed/epoch_sec : 1.0964 speed/samples_per_sec : 214.3468 \n",
      "test: CE : 0.0732 accuracy : 0.9826 speed/epoch_sec : 0.0281 speed/samples_per_sec : 1422.7987 \n",
      "epoch: 35\n",
      "train: CE : 0.0286 accuracy : 0.9918 speed/epoch_sec : 1.2685 speed/samples_per_sec : 185.2535 \n",
      "test: CE : 0.0941 accuracy : 0.9799 speed/epoch_sec : 0.0280 speed/samples_per_sec : 1429.0157 \n",
      "epoch: 36\n",
      "train: CE : 0.0279 accuracy : 0.9920 speed/epoch_sec : 1.3009 speed/samples_per_sec : 180.6414 \n",
      "test: CE : 0.0812 accuracy : 0.9822 speed/epoch_sec : 0.0280 speed/samples_per_sec : 1430.8682 \n",
      "epoch: 37\n",
      "train: CE : 0.0274 accuracy : 0.9913 speed/epoch_sec : 1.4058 speed/samples_per_sec : 167.1664 \n",
      "test: CE : 0.0796 accuracy : 0.9816 speed/epoch_sec : 0.0418 speed/samples_per_sec : 956.9810 \n",
      "epoch: 38\n",
      "train: CE : 0.0272 accuracy : 0.9917 speed/epoch_sec : 1.3818 speed/samples_per_sec : 170.0643 \n",
      "test: CE : 0.0872 accuracy : 0.9810 speed/epoch_sec : 0.0291 speed/samples_per_sec : 1372.3133 \n",
      "epoch: 39\n",
      "train: CE : 0.0249 accuracy : 0.9925 speed/epoch_sec : 1.2380 speed/samples_per_sec : 189.8270 \n",
      "test: CE : 0.0812 accuracy : 0.9822 speed/epoch_sec : 0.0269 speed/samples_per_sec : 1486.5380 \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>â–ˆâ–…â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–…â–„â–‚â–‚â–…â–…â–ƒâ–ƒâ–‚â–…â–„â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–„â–ƒ</td></tr><tr><td>CE/train</td><td>â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>accuracy/eval</td><td>â–â–ƒâ–…â–„â–…â–…â–†â–†â–†â–…â–†â–†â–‡â–‡â–‡â–†â–†â–…â–†â–‡â–ˆâ–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡</td></tr><tr><td>accuracy/train</td><td>â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>speed/epoch_sec/eval</td><td>â–â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–…â–‚â–â–‚â–â–â–â–â–â–â–ƒâ–ƒâ–‚â–â–…â–‚â–â–â–â–‚â–â–â–‚â–â–ˆâ–â–â–â–â–ƒâ–â–</td></tr><tr><td>speed/epoch_sec/train</td><td>â–‚â–ƒâ–…â–†â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–†â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–„â–â–‚â–„â–â–â–‚â–†â–‚â–ˆâ–…â–ƒâ–„â–…â–‚â–„â–…â–†â–†â–„</td></tr><tr><td>speed/samples_per_sec/eval</td><td>â–ˆâ–…â–†â–†â–„â–ˆâ–…â–‡â–ƒâ–…â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–„â–„â–†â–‡â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–‡â–†â–‡â–â–‡â–‡â–‡â–‡â–„â–‡â–ˆ</td></tr><tr><td>speed/samples_per_sec/train</td><td>â–‡â–…â–ƒâ–ƒâ–…â–†â–†â–†â–†â–‡â–‡â–‡â–ƒâ–†â–†â–‡â–…â–†â–†â–†â–„â–‡â–‡â–„â–ˆâ–ˆâ–‡â–‚â–‡â–â–„â–†â–„â–ƒâ–‡â–„â–„â–‚â–ƒâ–„</td></tr><tr><td>sys/ram_gb</td><td>â–‚â–â–â–‚â–â–ƒâ–‚â–‚â–„â–‚â–…â–‚â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>0.08123</td></tr><tr><td>CE/train</td><td>0.02493</td></tr><tr><td>accuracy/eval</td><td>0.9822</td></tr><tr><td>accuracy/train</td><td>0.99247</td></tr><tr><td>speed/epoch_sec/eval</td><td>0.02691</td></tr><tr><td>speed/epoch_sec/train</td><td>1.23797</td></tr><tr><td>speed/samples_per_sec/eval</td><td>1486.53795</td></tr><tr><td>speed/samples_per_sec/train</td><td>189.82702</td></tr><tr><td>sys/ram_gb</td><td>1.74598</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_tests</strong> at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/lleol8ne' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/lleol8ne</a><br> View project at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250728_235927-lleol8ne/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nik/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nik/deep_learning_projects/dqn_from_scratch/wandb/run-20250729_000019-pl1fsaku</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/pl1fsaku' target=\"_blank\">dropout_tests</a></strong> to <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/pl1fsaku' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/pl1fsaku</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: CE : 0.3185 accuracy : 0.9001 speed/epoch_sec : 1.3825 speed/samples_per_sec : 169.9822 \n",
      "test: CE : 0.1305 accuracy : 0.9583 speed/epoch_sec : 0.0272 speed/samples_per_sec : 1473.1976 \n",
      "epoch: 1\n",
      "train: CE : 0.1468 accuracy : 0.9551 speed/epoch_sec : 1.1688 speed/samples_per_sec : 201.0554 \n",
      "test: CE : 0.0954 accuracy : 0.9722 speed/epoch_sec : 0.0443 speed/samples_per_sec : 901.9766 \n",
      "epoch: 2\n",
      "train: CE : 0.1162 accuracy : 0.9643 speed/epoch_sec : 1.1777 speed/samples_per_sec : 199.5370 \n",
      "test: CE : 0.0872 accuracy : 0.9734 speed/epoch_sec : 0.0653 speed/samples_per_sec : 612.9268 \n",
      "epoch: 3\n",
      "train: CE : 0.1022 accuracy : 0.9680 speed/epoch_sec : 1.2234 speed/samples_per_sec : 192.0900 \n",
      "test: CE : 0.0870 accuracy : 0.9749 speed/epoch_sec : 0.0416 speed/samples_per_sec : 962.3992 \n",
      "epoch: 4\n",
      "train: CE : 0.0916 accuracy : 0.9711 speed/epoch_sec : 1.4599 speed/samples_per_sec : 160.9674 \n",
      "test: CE : 0.0767 accuracy : 0.9781 speed/epoch_sec : 0.0293 speed/samples_per_sec : 1364.3230 \n",
      "epoch: 5\n",
      "train: CE : 0.0839 accuracy : 0.9733 speed/epoch_sec : 1.2904 speed/samples_per_sec : 182.1072 \n",
      "test: CE : 0.0769 accuracy : 0.9769 speed/epoch_sec : 0.0293 speed/samples_per_sec : 1365.8669 \n",
      "epoch: 6\n",
      "train: CE : 0.0740 accuracy : 0.9772 speed/epoch_sec : 1.4804 speed/samples_per_sec : 158.7456 \n",
      "test: CE : 0.0777 accuracy : 0.9755 speed/epoch_sec : 0.0457 speed/samples_per_sec : 874.8157 \n",
      "epoch: 7\n",
      "train: CE : 0.0704 accuracy : 0.9779 speed/epoch_sec : 1.2227 speed/samples_per_sec : 192.1902 \n",
      "test: CE : 0.0741 accuracy : 0.9782 speed/epoch_sec : 0.0299 speed/samples_per_sec : 1339.8513 \n",
      "epoch: 8\n",
      "train: CE : 0.0682 accuracy : 0.9778 speed/epoch_sec : 1.2046 speed/samples_per_sec : 195.0898 \n",
      "test: CE : 0.0730 accuracy : 0.9782 speed/epoch_sec : 0.0296 speed/samples_per_sec : 1350.0508 \n",
      "epoch: 9\n",
      "train: CE : 0.0655 accuracy : 0.9788 speed/epoch_sec : 1.1965 speed/samples_per_sec : 196.3984 \n",
      "test: CE : 0.0755 accuracy : 0.9791 speed/epoch_sec : 0.0315 speed/samples_per_sec : 1269.4913 \n",
      "epoch: 10\n",
      "train: CE : 0.0612 accuracy : 0.9803 speed/epoch_sec : 1.2362 speed/samples_per_sec : 190.1049 \n",
      "test: CE : 0.0709 accuracy : 0.9800 speed/epoch_sec : 0.0311 speed/samples_per_sec : 1286.7838 \n",
      "epoch: 11\n",
      "train: CE : 0.0555 accuracy : 0.9824 speed/epoch_sec : 1.3623 speed/samples_per_sec : 172.5000 \n",
      "test: CE : 0.0817 accuracy : 0.9790 speed/epoch_sec : 0.0316 speed/samples_per_sec : 1266.5873 \n",
      "epoch: 12\n",
      "train: CE : 0.0591 accuracy : 0.9818 speed/epoch_sec : 1.6194 speed/samples_per_sec : 145.1170 \n",
      "test: CE : 0.0661 accuracy : 0.9801 speed/epoch_sec : 0.0373 speed/samples_per_sec : 1073.7624 \n",
      "epoch: 13\n",
      "train: CE : 0.0589 accuracy : 0.9813 speed/epoch_sec : 1.2059 speed/samples_per_sec : 194.8683 \n",
      "test: CE : 0.0707 accuracy : 0.9810 speed/epoch_sec : 0.0341 speed/samples_per_sec : 1174.3734 \n",
      "epoch: 14\n",
      "train: CE : 0.0539 accuracy : 0.9828 speed/epoch_sec : 1.2536 speed/samples_per_sec : 187.4600 \n",
      "test: CE : 0.0760 accuracy : 0.9807 speed/epoch_sec : 0.0301 speed/samples_per_sec : 1327.6790 \n",
      "epoch: 15\n",
      "train: CE : 0.0533 accuracy : 0.9828 speed/epoch_sec : 1.1066 speed/samples_per_sec : 212.3553 \n",
      "test: CE : 0.0676 accuracy : 0.9825 speed/epoch_sec : 0.0321 speed/samples_per_sec : 1247.4045 \n",
      "epoch: 16\n",
      "train: CE : 0.0500 accuracy : 0.9841 speed/epoch_sec : 1.0593 speed/samples_per_sec : 221.8517 \n",
      "test: CE : 0.0676 accuracy : 0.9826 speed/epoch_sec : 0.0277 speed/samples_per_sec : 1444.1579 \n",
      "epoch: 17\n",
      "train: CE : 0.0511 accuracy : 0.9836 speed/epoch_sec : 1.2411 speed/samples_per_sec : 189.3412 \n",
      "test: CE : 0.0683 accuracy : 0.9812 speed/epoch_sec : 0.0305 speed/samples_per_sec : 1311.9807 \n",
      "epoch: 18\n",
      "train: CE : 0.0481 accuracy : 0.9842 speed/epoch_sec : 1.3284 speed/samples_per_sec : 176.8990 \n",
      "test: CE : 0.0801 accuracy : 0.9787 speed/epoch_sec : 0.0307 speed/samples_per_sec : 1304.4931 \n",
      "epoch: 19\n",
      "train: CE : 0.0511 accuracy : 0.9837 speed/epoch_sec : 1.2636 speed/samples_per_sec : 185.9704 \n",
      "test: CE : 0.0688 accuracy : 0.9808 speed/epoch_sec : 0.0373 speed/samples_per_sec : 1071.7253 \n",
      "epoch: 20\n",
      "train: CE : 0.0458 accuracy : 0.9855 speed/epoch_sec : 1.4325 speed/samples_per_sec : 164.0543 \n",
      "test: CE : 0.0712 accuracy : 0.9817 speed/epoch_sec : 0.0334 speed/samples_per_sec : 1198.3127 \n",
      "epoch: 21\n",
      "train: CE : 0.0452 accuracy : 0.9855 speed/epoch_sec : 1.0977 speed/samples_per_sec : 214.0865 \n",
      "test: CE : 0.0686 accuracy : 0.9800 speed/epoch_sec : 0.0269 speed/samples_per_sec : 1485.6955 \n",
      "epoch: 22\n",
      "train: CE : 0.0465 accuracy : 0.9854 speed/epoch_sec : 1.2775 speed/samples_per_sec : 183.9528 \n",
      "test: CE : 0.0686 accuracy : 0.9813 speed/epoch_sec : 0.0344 speed/samples_per_sec : 1162.1790 \n",
      "epoch: 23\n",
      "train: CE : 0.0456 accuracy : 0.9853 speed/epoch_sec : 1.1593 speed/samples_per_sec : 202.7079 \n",
      "test: CE : 0.0753 accuracy : 0.9813 speed/epoch_sec : 0.0316 speed/samples_per_sec : 1264.3442 \n",
      "epoch: 24\n",
      "train: CE : 0.0435 accuracy : 0.9862 speed/epoch_sec : 1.1674 speed/samples_per_sec : 201.3054 \n",
      "test: CE : 0.0704 accuracy : 0.9804 speed/epoch_sec : 0.0325 speed/samples_per_sec : 1230.1996 \n",
      "epoch: 25\n",
      "train: CE : 0.0421 accuracy : 0.9868 speed/epoch_sec : 1.3715 speed/samples_per_sec : 171.3417 \n",
      "test: CE : 0.0684 accuracy : 0.9815 speed/epoch_sec : 0.0293 speed/samples_per_sec : 1365.1223 \n",
      "epoch: 26\n",
      "train: CE : 0.0418 accuracy : 0.9869 speed/epoch_sec : 1.5305 speed/samples_per_sec : 153.5448 \n",
      "test: CE : 0.0723 accuracy : 0.9818 speed/epoch_sec : 0.0275 speed/samples_per_sec : 1456.4188 \n",
      "epoch: 27\n",
      "train: CE : 0.0413 accuracy : 0.9872 speed/epoch_sec : 1.2994 speed/samples_per_sec : 180.8553 \n",
      "test: CE : 0.0755 accuracy : 0.9789 speed/epoch_sec : 0.0553 speed/samples_per_sec : 723.1122 \n",
      "epoch: 28\n",
      "train: CE : 0.0414 accuracy : 0.9872 speed/epoch_sec : 1.2433 speed/samples_per_sec : 189.0065 \n",
      "test: CE : 0.0750 accuracy : 0.9806 speed/epoch_sec : 0.0452 speed/samples_per_sec : 885.4627 \n",
      "epoch: 29\n",
      "train: CE : 0.0397 accuracy : 0.9872 speed/epoch_sec : 1.1989 speed/samples_per_sec : 196.0067 \n",
      "test: CE : 0.0828 accuracy : 0.9798 speed/epoch_sec : 0.0436 speed/samples_per_sec : 917.3642 \n",
      "epoch: 30\n",
      "train: CE : 0.0418 accuracy : 0.9867 speed/epoch_sec : 1.4477 speed/samples_per_sec : 162.3218 \n",
      "test: CE : 0.0724 accuracy : 0.9821 speed/epoch_sec : 0.0577 speed/samples_per_sec : 693.7234 \n",
      "epoch: 31\n",
      "train: CE : 0.0392 accuracy : 0.9874 speed/epoch_sec : 1.4989 speed/samples_per_sec : 156.7853 \n",
      "test: CE : 0.0782 accuracy : 0.9813 speed/epoch_sec : 0.0321 speed/samples_per_sec : 1247.2190 \n",
      "epoch: 32\n",
      "train: CE : 0.0397 accuracy : 0.9875 speed/epoch_sec : 1.1676 speed/samples_per_sec : 201.2647 \n",
      "test: CE : 0.0696 accuracy : 0.9817 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1411.2257 \n",
      "epoch: 33\n",
      "train: CE : 0.0396 accuracy : 0.9874 speed/epoch_sec : 1.1249 speed/samples_per_sec : 208.9119 \n",
      "test: CE : 0.0738 accuracy : 0.9810 speed/epoch_sec : 0.0296 speed/samples_per_sec : 1353.5689 \n",
      "epoch: 34\n",
      "train: CE : 0.0344 accuracy : 0.9891 speed/epoch_sec : 1.1940 speed/samples_per_sec : 196.8169 \n",
      "test: CE : 0.0755 accuracy : 0.9835 speed/epoch_sec : 0.0270 speed/samples_per_sec : 1484.0265 \n",
      "epoch: 35\n",
      "train: CE : 0.0357 accuracy : 0.9887 speed/epoch_sec : 1.1007 speed/samples_per_sec : 213.5031 \n",
      "test: CE : 0.0737 accuracy : 0.9816 speed/epoch_sec : 0.0257 speed/samples_per_sec : 1554.3814 \n",
      "epoch: 36\n",
      "train: CE : 0.0385 accuracy : 0.9883 speed/epoch_sec : 1.1041 speed/samples_per_sec : 212.8349 \n",
      "test: CE : 0.0782 accuracy : 0.9816 speed/epoch_sec : 0.0275 speed/samples_per_sec : 1452.3088 \n",
      "epoch: 37\n",
      "train: CE : 0.0371 accuracy : 0.9883 speed/epoch_sec : 1.1331 speed/samples_per_sec : 207.4023 \n",
      "test: CE : 0.0814 accuracy : 0.9806 speed/epoch_sec : 0.0291 speed/samples_per_sec : 1376.0727 \n",
      "epoch: 38\n",
      "train: CE : 0.0369 accuracy : 0.9886 speed/epoch_sec : 1.1472 speed/samples_per_sec : 204.8388 \n",
      "test: CE : 0.0798 accuracy : 0.9813 speed/epoch_sec : 0.0291 speed/samples_per_sec : 1375.3282 \n",
      "epoch: 39\n",
      "train: CE : 0.0370 accuracy : 0.9888 speed/epoch_sec : 1.0944 speed/samples_per_sec : 214.7241 \n",
      "test: CE : 0.0674 accuracy : 0.9838 speed/epoch_sec : 0.0277 speed/samples_per_sec : 1445.0660 \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–â–â–â–ƒâ–â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–</td></tr><tr><td>CE/train</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>accuracy/eval</td><td>â–â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>accuracy/train</td><td>â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>speed/epoch_sec/eval</td><td>â–â–„â–ˆâ–„â–‚â–‚â–…â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–â–†â–„â–„â–‡â–‚â–â–‚â–â–â–â–‚â–‚â–</td></tr><tr><td>speed/epoch_sec/train</td><td>â–…â–‚â–‚â–ƒâ–†â–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ˆâ–ƒâ–ƒâ–‚â–â–ƒâ–„â–„â–†â–â–„â–‚â–‚â–…â–‡â–„â–ƒâ–ƒâ–†â–†â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–</td></tr><tr><td>speed/samples_per_sec/eval</td><td>â–‡â–ƒâ–â–„â–‡â–‡â–ƒâ–†â–†â–†â–†â–†â–„â–…â–†â–†â–‡â–†â–†â–„â–…â–‡â–…â–†â–†â–‡â–‡â–‚â–ƒâ–ƒâ–‚â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡</td></tr><tr><td>speed/samples_per_sec/train</td><td>â–ƒâ–†â–†â–…â–‚â–„â–‚â–…â–†â–†â–…â–ƒâ–â–†â–…â–‡â–ˆâ–…â–„â–…â–ƒâ–‡â–…â–†â–†â–ƒâ–‚â–„â–…â–†â–ƒâ–‚â–†â–‡â–†â–‡â–‡â–‡â–†â–‡</td></tr><tr><td>sys/ram_gb</td><td>â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–†â–†â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>0.06743</td></tr><tr><td>CE/train</td><td>0.037</td></tr><tr><td>accuracy/eval</td><td>0.9838</td></tr><tr><td>accuracy/train</td><td>0.98878</td></tr><tr><td>speed/epoch_sec/eval</td><td>0.02768</td></tr><tr><td>speed/epoch_sec/train</td><td>1.09443</td></tr><tr><td>speed/samples_per_sec/eval</td><td>1445.06598</td></tr><tr><td>speed/samples_per_sec/train</td><td>214.72407</td></tr><tr><td>sys/ram_gb</td><td>1.6406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_tests</strong> at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/pl1fsaku' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/pl1fsaku</a><br> View project at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250729_000019-pl1fsaku/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nik/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nik/deep_learning_projects/dqn_from_scratch/wandb/run-20250729_000112-wu2l44mt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/wu2l44mt' target=\"_blank\">dropout_tests</a></strong> to <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/wu2l44mt' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/wu2l44mt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: CE : 0.3295 accuracy : 0.8973 speed/epoch_sec : 1.1908 speed/samples_per_sec : 197.3511 \n",
      "test: CE : 0.1267 accuracy : 0.9599 speed/epoch_sec : 0.0305 speed/samples_per_sec : 1310.4743 \n",
      "epoch: 1\n",
      "train: CE : 0.1617 accuracy : 0.9501 speed/epoch_sec : 1.2461 speed/samples_per_sec : 188.5888 \n",
      "test: CE : 0.1009 accuracy : 0.9682 speed/epoch_sec : 0.0316 speed/samples_per_sec : 1266.1094 \n",
      "epoch: 2\n",
      "train: CE : 0.1301 accuracy : 0.9592 speed/epoch_sec : 1.5102 speed/samples_per_sec : 155.6132 \n",
      "test: CE : 0.0928 accuracy : 0.9719 speed/epoch_sec : 0.0595 speed/samples_per_sec : 672.0133 \n",
      "epoch: 3\n",
      "train: CE : 0.1132 accuracy : 0.9643 speed/epoch_sec : 1.2265 speed/samples_per_sec : 191.6088 \n",
      "test: CE : 0.0848 accuracy : 0.9749 speed/epoch_sec : 0.0291 speed/samples_per_sec : 1375.6891 \n",
      "epoch: 4\n",
      "train: CE : 0.1027 accuracy : 0.9678 speed/epoch_sec : 1.1676 speed/samples_per_sec : 201.2646 \n",
      "test: CE : 0.0869 accuracy : 0.9751 speed/epoch_sec : 0.0302 speed/samples_per_sec : 1322.6757 \n",
      "epoch: 5\n",
      "train: CE : 0.0943 accuracy : 0.9707 speed/epoch_sec : 1.2111 speed/samples_per_sec : 194.0463 \n",
      "test: CE : 0.0732 accuracy : 0.9779 speed/epoch_sec : 0.0289 speed/samples_per_sec : 1384.5101 \n",
      "epoch: 6\n",
      "train: CE : 0.0871 accuracy : 0.9728 speed/epoch_sec : 1.4526 speed/samples_per_sec : 161.7841 \n",
      "test: CE : 0.0762 accuracy : 0.9772 speed/epoch_sec : 0.0755 speed/samples_per_sec : 529.8799 \n",
      "epoch: 7\n",
      "train: CE : 0.0854 accuracy : 0.9738 speed/epoch_sec : 1.2304 speed/samples_per_sec : 190.9929 \n",
      "test: CE : 0.0749 accuracy : 0.9778 speed/epoch_sec : 0.0480 speed/samples_per_sec : 833.9281 \n",
      "epoch: 8\n",
      "train: CE : 0.0793 accuracy : 0.9749 speed/epoch_sec : 1.3657 speed/samples_per_sec : 172.0697 \n",
      "test: CE : 0.0727 accuracy : 0.9777 speed/epoch_sec : 0.0284 speed/samples_per_sec : 1406.8354 \n",
      "epoch: 9\n",
      "train: CE : 0.0755 accuracy : 0.9762 speed/epoch_sec : 1.1021 speed/samples_per_sec : 213.2294 \n",
      "test: CE : 0.0703 accuracy : 0.9818 speed/epoch_sec : 0.0464 speed/samples_per_sec : 862.4266 \n",
      "epoch: 10\n",
      "train: CE : 0.0747 accuracy : 0.9765 speed/epoch_sec : 1.2098 speed/samples_per_sec : 194.2525 \n",
      "test: CE : 0.0641 accuracy : 0.9805 speed/epoch_sec : 0.0584 speed/samples_per_sec : 685.3802 \n",
      "epoch: 11\n",
      "train: CE : 0.0689 accuracy : 0.9776 speed/epoch_sec : 1.3288 speed/samples_per_sec : 176.8453 \n",
      "test: CE : 0.0689 accuracy : 0.9787 speed/epoch_sec : 0.0289 speed/samples_per_sec : 1382.0010 \n",
      "epoch: 12\n",
      "train: CE : 0.0706 accuracy : 0.9779 speed/epoch_sec : 1.0714 speed/samples_per_sec : 219.3419 \n",
      "test: CE : 0.0641 accuracy : 0.9815 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1359.1173 \n",
      "epoch: 13\n",
      "train: CE : 0.0676 accuracy : 0.9786 speed/epoch_sec : 1.1999 speed/samples_per_sec : 195.8543 \n",
      "test: CE : 0.0633 accuracy : 0.9814 speed/epoch_sec : 0.0342 speed/samples_per_sec : 1168.4437 \n",
      "epoch: 14\n",
      "train: CE : 0.0658 accuracy : 0.9793 speed/epoch_sec : 1.0589 speed/samples_per_sec : 221.9212 \n",
      "test: CE : 0.0716 accuracy : 0.9803 speed/epoch_sec : 0.0303 speed/samples_per_sec : 1319.9493 \n",
      "epoch: 15\n",
      "train: CE : 0.0652 accuracy : 0.9800 speed/epoch_sec : 1.0800 speed/samples_per_sec : 217.5922 \n",
      "test: CE : 0.0710 accuracy : 0.9789 speed/epoch_sec : 0.0274 speed/samples_per_sec : 1461.7228 \n",
      "epoch: 16\n",
      "train: CE : 0.0631 accuracy : 0.9799 speed/epoch_sec : 1.0555 speed/samples_per_sec : 222.6517 \n",
      "test: CE : 0.0669 accuracy : 0.9801 speed/epoch_sec : 0.0284 speed/samples_per_sec : 1408.3707 \n",
      "epoch: 17\n",
      "train: CE : 0.0589 accuracy : 0.9809 speed/epoch_sec : 1.0919 speed/samples_per_sec : 215.2296 \n",
      "test: CE : 0.0672 accuracy : 0.9819 speed/epoch_sec : 0.0391 speed/samples_per_sec : 1021.9728 \n",
      "epoch: 18\n",
      "train: CE : 0.0593 accuracy : 0.9819 speed/epoch_sec : 1.0633 speed/samples_per_sec : 221.0197 \n",
      "test: CE : 0.0697 accuracy : 0.9819 speed/epoch_sec : 0.0327 speed/samples_per_sec : 1223.0342 \n",
      "epoch: 19\n",
      "train: CE : 0.0583 accuracy : 0.9814 speed/epoch_sec : 1.0651 speed/samples_per_sec : 220.6454 \n",
      "test: CE : 0.0657 accuracy : 0.9811 speed/epoch_sec : 0.0302 speed/samples_per_sec : 1325.6438 \n",
      "epoch: 20\n",
      "train: CE : 0.0539 accuracy : 0.9829 speed/epoch_sec : 1.1725 speed/samples_per_sec : 200.4269 \n",
      "test: CE : 0.0621 accuracy : 0.9816 speed/epoch_sec : 0.0305 speed/samples_per_sec : 1309.8502 \n",
      "epoch: 21\n",
      "train: CE : 0.0569 accuracy : 0.9823 speed/epoch_sec : 1.1489 speed/samples_per_sec : 204.5408 \n",
      "test: CE : 0.0643 accuracy : 0.9813 speed/epoch_sec : 0.0311 speed/samples_per_sec : 1285.8370 \n",
      "epoch: 22\n",
      "train: CE : 0.0551 accuracy : 0.9829 speed/epoch_sec : 1.0494 speed/samples_per_sec : 223.9420 \n",
      "test: CE : 0.0623 accuracy : 0.9817 speed/epoch_sec : 0.0301 speed/samples_per_sec : 1329.6678 \n",
      "epoch: 23\n",
      "train: CE : 0.0557 accuracy : 0.9826 speed/epoch_sec : 1.0304 speed/samples_per_sec : 228.0622 \n",
      "test: CE : 0.0651 accuracy : 0.9818 speed/epoch_sec : 0.0316 speed/samples_per_sec : 1264.0108 \n",
      "epoch: 24\n",
      "train: CE : 0.0545 accuracy : 0.9829 speed/epoch_sec : 1.0333 speed/samples_per_sec : 227.4291 \n",
      "test: CE : 0.0684 accuracy : 0.9809 speed/epoch_sec : 0.0282 speed/samples_per_sec : 1416.4204 \n",
      "epoch: 25\n",
      "train: CE : 0.0571 accuracy : 0.9825 speed/epoch_sec : 1.0425 speed/samples_per_sec : 225.4254 \n",
      "test: CE : 0.0592 accuracy : 0.9831 speed/epoch_sec : 0.0313 speed/samples_per_sec : 1279.9902 \n",
      "epoch: 26\n",
      "train: CE : 0.0510 accuracy : 0.9839 speed/epoch_sec : 1.0720 speed/samples_per_sec : 219.2105 \n",
      "test: CE : 0.0592 accuracy : 0.9834 speed/epoch_sec : 0.0288 speed/samples_per_sec : 1388.0495 \n",
      "epoch: 27\n",
      "train: CE : 0.0506 accuracy : 0.9846 speed/epoch_sec : 1.1114 speed/samples_per_sec : 211.4370 \n",
      "test: CE : 0.0652 accuracy : 0.9826 speed/epoch_sec : 0.0298 speed/samples_per_sec : 1343.2411 \n",
      "epoch: 28\n",
      "train: CE : 0.0505 accuracy : 0.9846 speed/epoch_sec : 1.1245 speed/samples_per_sec : 208.9884 \n",
      "test: CE : 0.0695 accuracy : 0.9831 speed/epoch_sec : 0.0315 speed/samples_per_sec : 1269.5009 \n",
      "epoch: 29\n",
      "train: CE : 0.0494 accuracy : 0.9839 speed/epoch_sec : 1.2424 speed/samples_per_sec : 189.1449 \n",
      "test: CE : 0.0670 accuracy : 0.9832 speed/epoch_sec : 0.0293 speed/samples_per_sec : 1363.7020 \n",
      "epoch: 30\n",
      "train: CE : 0.0503 accuracy : 0.9844 speed/epoch_sec : 1.0628 speed/samples_per_sec : 221.1091 \n",
      "test: CE : 0.0679 accuracy : 0.9836 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1414.0447 \n",
      "epoch: 31\n",
      "train: CE : 0.0496 accuracy : 0.9853 speed/epoch_sec : 1.0523 speed/samples_per_sec : 223.3145 \n",
      "test: CE : 0.0665 accuracy : 0.9818 speed/epoch_sec : 0.0280 speed/samples_per_sec : 1426.3308 \n",
      "epoch: 32\n",
      "train: CE : 0.0503 accuracy : 0.9847 speed/epoch_sec : 1.0455 speed/samples_per_sec : 224.7780 \n",
      "test: CE : 0.0600 accuracy : 0.9838 speed/epoch_sec : 0.0281 speed/samples_per_sec : 1423.2333 \n",
      "epoch: 33\n",
      "train: CE : 0.0512 accuracy : 0.9840 speed/epoch_sec : 1.1189 speed/samples_per_sec : 210.0274 \n",
      "test: CE : 0.0635 accuracy : 0.9838 speed/epoch_sec : 0.0285 speed/samples_per_sec : 1404.5035 \n",
      "epoch: 34\n",
      "train: CE : 0.0487 accuracy : 0.9846 speed/epoch_sec : 1.0891 speed/samples_per_sec : 215.7705 \n",
      "test: CE : 0.0655 accuracy : 0.9828 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1359.9326 \n",
      "epoch: 35\n",
      "train: CE : 0.0475 accuracy : 0.9851 speed/epoch_sec : 1.0624 speed/samples_per_sec : 221.1948 \n",
      "test: CE : 0.0605 accuracy : 0.9827 speed/epoch_sec : 0.0303 speed/samples_per_sec : 1319.3992 \n",
      "epoch: 36\n",
      "train: CE : 0.0466 accuracy : 0.9854 speed/epoch_sec : 1.0400 speed/samples_per_sec : 225.9546 \n",
      "test: CE : 0.0661 accuracy : 0.9825 speed/epoch_sec : 0.0288 speed/samples_per_sec : 1386.7760 \n",
      "epoch: 37\n",
      "train: CE : 0.0450 accuracy : 0.9860 speed/epoch_sec : 1.0365 speed/samples_per_sec : 226.7321 \n",
      "test: CE : 0.0631 accuracy : 0.9835 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1360.3626 \n",
      "epoch: 38\n",
      "train: CE : 0.0450 accuracy : 0.9860 speed/epoch_sec : 1.2868 speed/samples_per_sec : 182.6191 \n",
      "test: CE : 0.0593 accuracy : 0.9843 speed/epoch_sec : 0.0495 speed/samples_per_sec : 807.4276 \n",
      "epoch: 39\n",
      "train: CE : 0.0462 accuracy : 0.9864 speed/epoch_sec : 1.1179 speed/samples_per_sec : 210.2245 \n",
      "test: CE : 0.0665 accuracy : 0.9828 speed/epoch_sec : 0.0289 speed/samples_per_sec : 1381.7165 \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>â–ˆâ–…â–„â–„â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–‚</td></tr><tr><td>CE/train</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>accuracy/eval</td><td>â–â–ƒâ–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>accuracy/train</td><td>â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>speed/epoch_sec/eval</td><td>â–â–‚â–†â–â–â–â–ˆâ–„â–â–„â–†â–â–â–‚â–â–â–â–ƒâ–‚â–â–â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–„â–</td></tr><tr><td>speed/epoch_sec/train</td><td>â–ƒâ–„â–ˆâ–„â–ƒâ–„â–‡â–„â–†â–‚â–„â–…â–‚â–ƒâ–â–‚â–â–‚â–â–‚â–ƒâ–ƒâ–â–â–â–â–‚â–‚â–‚â–„â–â–â–â–‚â–‚â–â–â–â–…â–‚</td></tr><tr><td>speed/samples_per_sec/eval</td><td>â–‡â–‡â–‚â–‡â–‡â–‡â–â–ƒâ–ˆâ–ƒâ–‚â–‡â–‡â–†â–‡â–ˆâ–ˆâ–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ƒâ–‡</td></tr><tr><td>speed/samples_per_sec/train</td><td>â–…â–„â–â–„â–…â–…â–‚â–„â–ƒâ–‡â–…â–ƒâ–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–„â–‡â–ˆâ–ˆâ–†â–‡â–‡â–ˆâ–ˆâ–„â–†</td></tr><tr><td>sys/ram_gb</td><td>â–â–‚â–‚â–‚â–ƒâ–ƒâ–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>0.06653</td></tr><tr><td>CE/train</td><td>0.04621</td></tr><tr><td>accuracy/eval</td><td>0.9828</td></tr><tr><td>accuracy/train</td><td>0.98637</td></tr><tr><td>speed/epoch_sec/eval</td><td>0.02895</td></tr><tr><td>speed/epoch_sec/train</td><td>1.11785</td></tr><tr><td>speed/samples_per_sec/eval</td><td>1381.71648</td></tr><tr><td>speed/samples_per_sec/train</td><td>210.22448</td></tr><tr><td>sys/ram_gb</td><td>1.74432</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_tests</strong> at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/wu2l44mt' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/wu2l44mt</a><br> View project at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250729_000112-wu2l44mt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nik/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nik/deep_learning_projects/dqn_from_scratch/wandb/run-20250729_000201-9vrp10ow</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/9vrp10ow' target=\"_blank\">dropout_tests</a></strong> to <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/9vrp10ow' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/9vrp10ow</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: CE : 0.3565 accuracy : 0.8881 speed/epoch_sec : 1.0327 speed/samples_per_sec : 227.5601 \n",
      "test: CE : 0.1335 accuracy : 0.9585 speed/epoch_sec : 0.0343 speed/samples_per_sec : 1167.3787 \n",
      "epoch: 1\n",
      "train: CE : 0.1843 accuracy : 0.9426 speed/epoch_sec : 1.1019 speed/samples_per_sec : 213.2756 \n",
      "test: CE : 0.1009 accuracy : 0.9685 speed/epoch_sec : 0.0281 speed/samples_per_sec : 1424.1152 \n",
      "epoch: 2\n",
      "train: CE : 0.1500 accuracy : 0.9527 speed/epoch_sec : 1.0297 speed/samples_per_sec : 228.2309 \n",
      "test: CE : 0.0939 accuracy : 0.9713 speed/epoch_sec : 0.0289 speed/samples_per_sec : 1381.9555 \n",
      "epoch: 3\n",
      "train: CE : 0.1342 accuracy : 0.9584 speed/epoch_sec : 0.9704 speed/samples_per_sec : 242.1700 \n",
      "test: CE : 0.0934 accuracy : 0.9702 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1361.4223 \n",
      "epoch: 4\n",
      "train: CE : 0.1251 accuracy : 0.9608 speed/epoch_sec : 1.0138 speed/samples_per_sec : 231.8050 \n",
      "test: CE : 0.0827 accuracy : 0.9756 speed/epoch_sec : 0.0272 speed/samples_per_sec : 1468.7095 \n",
      "epoch: 5\n",
      "train: CE : 0.1170 accuracy : 0.9632 speed/epoch_sec : 1.0644 speed/samples_per_sec : 220.7725 \n",
      "test: CE : 0.0862 accuracy : 0.9749 speed/epoch_sec : 0.0264 speed/samples_per_sec : 1514.2848 \n",
      "epoch: 6\n",
      "train: CE : 0.1113 accuracy : 0.9652 speed/epoch_sec : 1.4137 speed/samples_per_sec : 166.2327 \n",
      "test: CE : 0.0787 accuracy : 0.9774 speed/epoch_sec : 0.0301 speed/samples_per_sec : 1328.0258 \n",
      "epoch: 7\n",
      "train: CE : 0.1058 accuracy : 0.9671 speed/epoch_sec : 1.0692 speed/samples_per_sec : 219.7939 \n",
      "test: CE : 0.0789 accuracy : 0.9764 speed/epoch_sec : 0.0278 speed/samples_per_sec : 1439.0421 \n",
      "epoch: 8\n",
      "train: CE : 0.1001 accuracy : 0.9683 speed/epoch_sec : 1.0282 speed/samples_per_sec : 228.5601 \n",
      "test: CE : 0.0673 accuracy : 0.9788 speed/epoch_sec : 0.0292 speed/samples_per_sec : 1367.9160 \n",
      "epoch: 9\n",
      "train: CE : 0.0955 accuracy : 0.9700 speed/epoch_sec : 1.2097 speed/samples_per_sec : 194.2702 \n",
      "test: CE : 0.0728 accuracy : 0.9784 speed/epoch_sec : 0.0278 speed/samples_per_sec : 1437.6856 \n",
      "epoch: 10\n",
      "train: CE : 0.0903 accuracy : 0.9713 speed/epoch_sec : 0.9667 speed/samples_per_sec : 243.1006 \n",
      "test: CE : 0.0699 accuracy : 0.9773 speed/epoch_sec : 0.0271 speed/samples_per_sec : 1475.3611 \n",
      "epoch: 11\n",
      "train: CE : 0.0890 accuracy : 0.9725 speed/epoch_sec : 0.9569 speed/samples_per_sec : 245.5850 \n",
      "test: CE : 0.0694 accuracy : 0.9804 speed/epoch_sec : 0.0263 speed/samples_per_sec : 1519.8130 \n",
      "epoch: 12\n",
      "train: CE : 0.0857 accuracy : 0.9720 speed/epoch_sec : 1.1740 speed/samples_per_sec : 200.1757 \n",
      "test: CE : 0.0654 accuracy : 0.9807 speed/epoch_sec : 0.0284 speed/samples_per_sec : 1410.8341 \n",
      "epoch: 13\n",
      "train: CE : 0.0822 accuracy : 0.9739 speed/epoch_sec : 1.1119 speed/samples_per_sec : 211.3591 \n",
      "test: CE : 0.0613 accuracy : 0.9822 speed/epoch_sec : 0.0430 speed/samples_per_sec : 929.9236 \n",
      "epoch: 14\n",
      "train: CE : 0.0815 accuracy : 0.9737 speed/epoch_sec : 1.1360 speed/samples_per_sec : 206.8740 \n",
      "test: CE : 0.0646 accuracy : 0.9818 speed/epoch_sec : 0.0327 speed/samples_per_sec : 1224.2479 \n",
      "epoch: 15\n",
      "train: CE : 0.0809 accuracy : 0.9749 speed/epoch_sec : 1.2850 speed/samples_per_sec : 182.8845 \n",
      "test: CE : 0.0651 accuracy : 0.9810 speed/epoch_sec : 0.0269 speed/samples_per_sec : 1487.8695 \n",
      "epoch: 16\n",
      "train: CE : 0.0781 accuracy : 0.9755 speed/epoch_sec : 1.1145 speed/samples_per_sec : 210.8525 \n",
      "test: CE : 0.0627 accuracy : 0.9819 speed/epoch_sec : 0.0280 speed/samples_per_sec : 1429.1983 \n",
      "epoch: 17\n",
      "train: CE : 0.0754 accuracy : 0.9763 speed/epoch_sec : 1.1995 speed/samples_per_sec : 195.9194 \n",
      "test: CE : 0.0653 accuracy : 0.9833 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1360.7157 \n",
      "epoch: 18\n",
      "train: CE : 0.0762 accuracy : 0.9765 speed/epoch_sec : 1.2830 speed/samples_per_sec : 183.1588 \n",
      "test: CE : 0.0648 accuracy : 0.9809 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1412.1879 \n",
      "epoch: 19\n",
      "train: CE : 0.0725 accuracy : 0.9770 speed/epoch_sec : 1.0779 speed/samples_per_sec : 218.0198 \n",
      "test: CE : 0.0683 accuracy : 0.9812 speed/epoch_sec : 0.0280 speed/samples_per_sec : 1428.8575 \n",
      "epoch: 20\n",
      "train: CE : 0.0759 accuracy : 0.9768 speed/epoch_sec : 1.1387 speed/samples_per_sec : 206.3846 \n",
      "test: CE : 0.0681 accuracy : 0.9812 speed/epoch_sec : 0.0297 speed/samples_per_sec : 1347.7191 \n",
      "epoch: 21\n",
      "train: CE : 0.0717 accuracy : 0.9770 speed/epoch_sec : 1.1189 speed/samples_per_sec : 210.0245 \n",
      "test: CE : 0.0618 accuracy : 0.9835 speed/epoch_sec : 0.0267 speed/samples_per_sec : 1495.9489 \n",
      "epoch: 22\n",
      "train: CE : 0.0694 accuracy : 0.9781 speed/epoch_sec : 1.0040 speed/samples_per_sec : 234.0571 \n",
      "test: CE : 0.0732 accuracy : 0.9813 speed/epoch_sec : 0.0319 speed/samples_per_sec : 1255.4601 \n",
      "epoch: 23\n",
      "train: CE : 0.0705 accuracy : 0.9777 speed/epoch_sec : 1.0586 speed/samples_per_sec : 222.0006 \n",
      "test: CE : 0.0727 accuracy : 0.9796 speed/epoch_sec : 0.0266 speed/samples_per_sec : 1504.5076 \n",
      "epoch: 24\n",
      "train: CE : 0.0674 accuracy : 0.9790 speed/epoch_sec : 1.3188 speed/samples_per_sec : 178.1937 \n",
      "test: CE : 0.0621 accuracy : 0.9825 speed/epoch_sec : 0.0467 speed/samples_per_sec : 855.7927 \n",
      "epoch: 25\n",
      "train: CE : 0.0679 accuracy : 0.9791 speed/epoch_sec : 1.1281 speed/samples_per_sec : 208.3159 \n",
      "test: CE : 0.0584 accuracy : 0.9847 speed/epoch_sec : 0.0269 speed/samples_per_sec : 1486.6960 \n",
      "epoch: 26\n",
      "train: CE : 0.0679 accuracy : 0.9788 speed/epoch_sec : 1.1071 speed/samples_per_sec : 212.2610 \n",
      "test: CE : 0.0599 accuracy : 0.9844 speed/epoch_sec : 0.0268 speed/samples_per_sec : 1491.2153 \n",
      "epoch: 27\n",
      "train: CE : 0.0654 accuracy : 0.9797 speed/epoch_sec : 0.9934 speed/samples_per_sec : 236.5643 \n",
      "test: CE : 0.0599 accuracy : 0.9846 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1359.9105 \n",
      "epoch: 28\n",
      "train: CE : 0.0668 accuracy : 0.9788 speed/epoch_sec : 0.9876 speed/samples_per_sec : 237.9525 \n",
      "test: CE : 0.0648 accuracy : 0.9823 speed/epoch_sec : 0.0268 speed/samples_per_sec : 1491.2683 \n",
      "epoch: 29\n",
      "train: CE : 0.0660 accuracy : 0.9791 speed/epoch_sec : 1.1485 speed/samples_per_sec : 204.6083 \n",
      "test: CE : 0.0606 accuracy : 0.9845 speed/epoch_sec : 0.0303 speed/samples_per_sec : 1321.1239 \n",
      "epoch: 30\n",
      "train: CE : 0.0637 accuracy : 0.9800 speed/epoch_sec : 1.0903 speed/samples_per_sec : 215.5311 \n",
      "test: CE : 0.0613 accuracy : 0.9844 speed/epoch_sec : 0.0271 speed/samples_per_sec : 1476.3088 \n",
      "epoch: 31\n",
      "train: CE : 0.0618 accuracy : 0.9814 speed/epoch_sec : 0.9898 speed/samples_per_sec : 237.4225 \n",
      "test: CE : 0.0613 accuracy : 0.9848 speed/epoch_sec : 0.0315 speed/samples_per_sec : 1269.7219 \n",
      "epoch: 32\n",
      "train: CE : 0.0591 accuracy : 0.9814 speed/epoch_sec : 0.9910 speed/samples_per_sec : 237.1273 \n",
      "test: CE : 0.0624 accuracy : 0.9834 speed/epoch_sec : 0.0315 speed/samples_per_sec : 1268.5506 \n",
      "epoch: 33\n",
      "train: CE : 0.0622 accuracy : 0.9809 speed/epoch_sec : 1.2873 speed/samples_per_sec : 182.5462 \n",
      "test: CE : 0.0647 accuracy : 0.9823 speed/epoch_sec : 0.0301 speed/samples_per_sec : 1329.5519 \n",
      "epoch: 34\n",
      "train: CE : 0.0623 accuracy : 0.9803 speed/epoch_sec : 1.5886 speed/samples_per_sec : 147.9277 \n",
      "test: CE : 0.0624 accuracy : 0.9827 speed/epoch_sec : 0.0367 speed/samples_per_sec : 1089.9888 \n",
      "epoch: 35\n",
      "train: CE : 0.0602 accuracy : 0.9813 speed/epoch_sec : 1.3545 speed/samples_per_sec : 173.4983 \n",
      "test: CE : 0.0640 accuracy : 0.9840 speed/epoch_sec : 0.1314 speed/samples_per_sec : 304.5215 \n",
      "epoch: 36\n",
      "train: CE : 0.0616 accuracy : 0.9807 speed/epoch_sec : 1.1088 speed/samples_per_sec : 211.9380 \n",
      "test: CE : 0.0695 accuracy : 0.9836 speed/epoch_sec : 0.0275 speed/samples_per_sec : 1457.1651 \n",
      "epoch: 37\n",
      "train: CE : 0.0607 accuracy : 0.9812 speed/epoch_sec : 1.3433 speed/samples_per_sec : 174.9436 \n",
      "test: CE : 0.0682 accuracy : 0.9824 speed/epoch_sec : 0.0419 speed/samples_per_sec : 954.8188 \n",
      "epoch: 38\n",
      "train: CE : 0.0616 accuracy : 0.9804 speed/epoch_sec : 1.2731 speed/samples_per_sec : 184.5947 \n",
      "test: CE : 0.0558 accuracy : 0.9848 speed/epoch_sec : 0.0277 speed/samples_per_sec : 1442.9655 \n",
      "epoch: 39\n",
      "train: CE : 0.0595 accuracy : 0.9818 speed/epoch_sec : 1.2650 speed/samples_per_sec : 185.7745 \n",
      "test: CE : 0.0538 accuracy : 0.9855 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1411.3563 \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>â–ˆâ–…â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>CE/train</td><td>â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>accuracy/eval</td><td>â–â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ</td></tr><tr><td>accuracy/train</td><td>â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>speed/epoch_sec/eval</td><td>â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–ˆâ–â–‚â–â–</td></tr><tr><td>speed/epoch_sec/train</td><td>â–‚â–ƒâ–‚â–â–‚â–‚â–†â–‚â–‚â–„â–â–â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–‚â–…â–ƒâ–ƒâ–â–â–ƒâ–‚â–â–â–…â–ˆâ–…â–ƒâ–…â–…â–„</td></tr><tr><td>speed/samples_per_sec/eval</td><td>â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–ˆâ–„â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–â–ˆâ–…â–ˆâ–‡</td></tr><tr><td>speed/samples_per_sec/train</td><td>â–‡â–†â–‡â–ˆâ–‡â–†â–‚â–†â–‡â–„â–ˆâ–ˆâ–…â–†â–…â–„â–†â–„â–„â–†â–…â–…â–‡â–†â–ƒâ–…â–†â–‡â–‡â–…â–†â–‡â–‡â–ƒâ–â–ƒâ–†â–ƒâ–„â–„</td></tr><tr><td>sys/ram_gb</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–â–ƒâ–ƒâ–†â–„â–ƒâ–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>0.05381</td></tr><tr><td>CE/train</td><td>0.05953</td></tr><tr><td>accuracy/eval</td><td>0.9855</td></tr><tr><td>accuracy/train</td><td>0.98178</td></tr><tr><td>speed/epoch_sec/eval</td><td>0.02834</td></tr><tr><td>speed/epoch_sec/train</td><td>1.26497</td></tr><tr><td>speed/samples_per_sec/eval</td><td>1411.35632</td></tr><tr><td>speed/samples_per_sec/train</td><td>185.77448</td></tr><tr><td>sys/ram_gb</td><td>1.76048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_tests</strong> at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/9vrp10ow' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/9vrp10ow</a><br> View project at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250729_000201-9vrp10ow/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/nik/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nik/deep_learning_projects/dqn_from_scratch/wandb/run-20250729_000250-p5zy13dl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/p5zy13dl' target=\"_blank\">dropout_tests</a></strong> to <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/p5zy13dl' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/p5zy13dl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train: CE : 0.3837 accuracy : 0.8805 speed/epoch_sec : 1.1467 speed/samples_per_sec : 204.9344 \n",
      "test: CE : 0.1246 accuracy : 0.9608 speed/epoch_sec : 0.0335 speed/samples_per_sec : 1192.8175 \n",
      "epoch: 1\n",
      "train: CE : 0.2037 accuracy : 0.9371 speed/epoch_sec : 1.1186 speed/samples_per_sec : 210.0756 \n",
      "test: CE : 0.1069 accuracy : 0.9681 speed/epoch_sec : 0.0278 speed/samples_per_sec : 1438.5979 \n",
      "epoch: 2\n",
      "train: CE : 0.1749 accuracy : 0.9459 speed/epoch_sec : 1.0646 speed/samples_per_sec : 220.7309 \n",
      "test: CE : 0.0908 accuracy : 0.9714 speed/epoch_sec : 0.0289 speed/samples_per_sec : 1383.7792 \n",
      "epoch: 3\n",
      "train: CE : 0.1518 accuracy : 0.9531 speed/epoch_sec : 1.2708 speed/samples_per_sec : 184.9285 \n",
      "test: CE : 0.0845 accuracy : 0.9748 speed/epoch_sec : 0.0276 speed/samples_per_sec : 1451.2409 \n",
      "epoch: 4\n",
      "train: CE : 0.1410 accuracy : 0.9560 speed/epoch_sec : 1.1643 speed/samples_per_sec : 201.8397 \n",
      "test: CE : 0.0811 accuracy : 0.9736 speed/epoch_sec : 0.0454 speed/samples_per_sec : 880.5458 \n",
      "epoch: 5\n",
      "train: CE : 0.1289 accuracy : 0.9603 speed/epoch_sec : 1.0017 speed/samples_per_sec : 234.5974 \n",
      "test: CE : 0.0760 accuracy : 0.9762 speed/epoch_sec : 0.0296 speed/samples_per_sec : 1353.5252 \n",
      "epoch: 6\n",
      "train: CE : 0.1254 accuracy : 0.9611 speed/epoch_sec : 1.2093 speed/samples_per_sec : 194.3287 \n",
      "test: CE : 0.0744 accuracy : 0.9767 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1415.5480 \n",
      "epoch: 7\n",
      "train: CE : 0.1172 accuracy : 0.9629 speed/epoch_sec : 1.2731 speed/samples_per_sec : 184.5845 \n",
      "test: CE : 0.0804 accuracy : 0.9753 speed/epoch_sec : 0.0274 speed/samples_per_sec : 1457.4816 \n",
      "epoch: 8\n",
      "train: CE : 0.1102 accuracy : 0.9650 speed/epoch_sec : 1.5171 speed/samples_per_sec : 154.9005 \n",
      "test: CE : 0.0670 accuracy : 0.9793 speed/epoch_sec : 0.0326 speed/samples_per_sec : 1227.0325 \n",
      "epoch: 9\n",
      "train: CE : 0.1102 accuracy : 0.9648 speed/epoch_sec : 1.0937 speed/samples_per_sec : 214.8683 \n",
      "test: CE : 0.0662 accuracy : 0.9796 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1413.7587 \n",
      "epoch: 10\n",
      "train: CE : 0.1130 accuracy : 0.9646 speed/epoch_sec : 1.2933 speed/samples_per_sec : 181.7082 \n",
      "test: CE : 0.0681 accuracy : 0.9789 speed/epoch_sec : 0.0463 speed/samples_per_sec : 864.0166 \n",
      "epoch: 11\n",
      "train: CE : 0.1031 accuracy : 0.9677 speed/epoch_sec : 1.0364 speed/samples_per_sec : 226.7495 \n",
      "test: CE : 0.0707 accuracy : 0.9782 speed/epoch_sec : 0.0514 speed/samples_per_sec : 777.4608 \n",
      "epoch: 12\n",
      "train: CE : 0.1032 accuracy : 0.9679 speed/epoch_sec : 1.1023 speed/samples_per_sec : 213.1934 \n",
      "test: CE : 0.0630 accuracy : 0.9810 speed/epoch_sec : 0.0316 speed/samples_per_sec : 1267.6209 \n",
      "epoch: 13\n",
      "train: CE : 0.0984 accuracy : 0.9688 speed/epoch_sec : 1.0613 speed/samples_per_sec : 221.4238 \n",
      "test: CE : 0.0678 accuracy : 0.9798 speed/epoch_sec : 0.0345 speed/samples_per_sec : 1157.8319 \n",
      "epoch: 14\n",
      "train: CE : 0.0975 accuracy : 0.9699 speed/epoch_sec : 1.2064 speed/samples_per_sec : 194.7886 \n",
      "test: CE : 0.0600 accuracy : 0.9806 speed/epoch_sec : 0.0289 speed/samples_per_sec : 1383.4027 \n",
      "epoch: 15\n",
      "train: CE : 0.0972 accuracy : 0.9692 speed/epoch_sec : 1.1766 speed/samples_per_sec : 199.7251 \n",
      "test: CE : 0.0652 accuracy : 0.9802 speed/epoch_sec : 0.0508 speed/samples_per_sec : 787.9957 \n",
      "epoch: 16\n",
      "train: CE : 0.0940 accuracy : 0.9706 speed/epoch_sec : 1.0375 speed/samples_per_sec : 226.5001 \n",
      "test: CE : 0.0629 accuracy : 0.9809 speed/epoch_sec : 0.0282 speed/samples_per_sec : 1418.4682 \n",
      "epoch: 17\n",
      "train: CE : 0.0935 accuracy : 0.9704 speed/epoch_sec : 1.2193 speed/samples_per_sec : 192.7312 \n",
      "test: CE : 0.0626 accuracy : 0.9820 speed/epoch_sec : 0.0294 speed/samples_per_sec : 1360.7157 \n",
      "epoch: 18\n",
      "train: CE : 0.0935 accuracy : 0.9711 speed/epoch_sec : 1.1994 speed/samples_per_sec : 195.9280 \n",
      "test: CE : 0.0654 accuracy : 0.9808 speed/epoch_sec : 0.0288 speed/samples_per_sec : 1389.3830 \n",
      "epoch: 19\n",
      "train: CE : 0.0917 accuracy : 0.9706 speed/epoch_sec : 1.2987 speed/samples_per_sec : 180.9550 \n",
      "test: CE : 0.0634 accuracy : 0.9811 speed/epoch_sec : 0.0288 speed/samples_per_sec : 1387.4067 \n",
      "epoch: 20\n",
      "train: CE : 0.0882 accuracy : 0.9724 speed/epoch_sec : 0.9290 speed/samples_per_sec : 252.9544 \n",
      "test: CE : 0.0607 accuracy : 0.9819 speed/epoch_sec : 0.0270 speed/samples_per_sec : 1481.6412 \n",
      "epoch: 21\n",
      "train: CE : 0.0892 accuracy : 0.9716 speed/epoch_sec : 0.9271 speed/samples_per_sec : 253.4847 \n",
      "test: CE : 0.0608 accuracy : 0.9807 speed/epoch_sec : 0.0277 speed/samples_per_sec : 1444.6056 \n",
      "epoch: 22\n",
      "train: CE : 0.0862 accuracy : 0.9730 speed/epoch_sec : 1.0267 speed/samples_per_sec : 228.8830 \n",
      "test: CE : 0.0613 accuracy : 0.9822 speed/epoch_sec : 0.0269 speed/samples_per_sec : 1485.0642 \n",
      "epoch: 23\n",
      "train: CE : 0.0893 accuracy : 0.9718 speed/epoch_sec : 1.2448 speed/samples_per_sec : 188.7820 \n",
      "test: CE : 0.0634 accuracy : 0.9820 speed/epoch_sec : 0.0273 speed/samples_per_sec : 1465.0031 \n",
      "epoch: 24\n",
      "train: CE : 0.0838 accuracy : 0.9742 speed/epoch_sec : 1.0373 speed/samples_per_sec : 226.5430 \n",
      "test: CE : 0.0602 accuracy : 0.9822 speed/epoch_sec : 0.0275 speed/samples_per_sec : 1454.0583 \n",
      "epoch: 25\n",
      "train: CE : 0.0855 accuracy : 0.9732 speed/epoch_sec : 1.1694 speed/samples_per_sec : 200.9587 \n",
      "test: CE : 0.0581 accuracy : 0.9833 speed/epoch_sec : 0.0316 speed/samples_per_sec : 1267.5826 \n",
      "epoch: 26\n",
      "train: CE : 0.0794 accuracy : 0.9746 speed/epoch_sec : 1.6752 speed/samples_per_sec : 140.2786 \n",
      "test: CE : 0.0661 accuracy : 0.9811 speed/epoch_sec : 0.0673 speed/samples_per_sec : 594.5025 \n",
      "epoch: 27\n",
      "train: CE : 0.0842 accuracy : 0.9729 speed/epoch_sec : 1.3569 speed/samples_per_sec : 173.1847 \n",
      "test: CE : 0.0619 accuracy : 0.9818 speed/epoch_sec : 0.0449 speed/samples_per_sec : 890.6664 \n",
      "epoch: 28\n",
      "train: CE : 0.0833 accuracy : 0.9740 speed/epoch_sec : 1.0624 speed/samples_per_sec : 221.1928 \n",
      "test: CE : 0.0639 accuracy : 0.9812 speed/epoch_sec : 0.0287 speed/samples_per_sec : 1395.0207 \n",
      "epoch: 29\n",
      "train: CE : 0.0805 accuracy : 0.9750 speed/epoch_sec : 1.0248 speed/samples_per_sec : 229.3050 \n",
      "test: CE : 0.0605 accuracy : 0.9821 speed/epoch_sec : 0.0287 speed/samples_per_sec : 1391.4571 \n",
      "epoch: 30\n",
      "train: CE : 0.0804 accuracy : 0.9749 speed/epoch_sec : 1.1157 speed/samples_per_sec : 210.6341 \n",
      "test: CE : 0.0597 accuracy : 0.9824 speed/epoch_sec : 0.0277 speed/samples_per_sec : 1443.0897 \n",
      "epoch: 31\n",
      "train: CE : 0.0816 accuracy : 0.9749 speed/epoch_sec : 1.0533 speed/samples_per_sec : 223.1128 \n",
      "test: CE : 0.0615 accuracy : 0.9826 speed/epoch_sec : 0.0343 speed/samples_per_sec : 1165.1735 \n",
      "epoch: 32\n",
      "train: CE : 0.0769 accuracy : 0.9757 speed/epoch_sec : 1.0223 speed/samples_per_sec : 229.8734 \n",
      "test: CE : 0.0573 accuracy : 0.9835 speed/epoch_sec : 0.0277 speed/samples_per_sec : 1444.2325 \n",
      "epoch: 33\n",
      "train: CE : 0.0765 accuracy : 0.9760 speed/epoch_sec : 1.3599 speed/samples_per_sec : 172.8021 \n",
      "test: CE : 0.0570 accuracy : 0.9831 speed/epoch_sec : 0.0290 speed/samples_per_sec : 1379.8301 \n",
      "epoch: 34\n",
      "train: CE : 0.0782 accuracy : 0.9756 speed/epoch_sec : 1.2714 speed/samples_per_sec : 184.8348 \n",
      "test: CE : 0.0573 accuracy : 0.9833 speed/epoch_sec : 0.0270 speed/samples_per_sec : 1483.8296 \n",
      "epoch: 35\n",
      "train: CE : 0.0749 accuracy : 0.9760 speed/epoch_sec : 0.9776 speed/samples_per_sec : 240.3726 \n",
      "test: CE : 0.0615 accuracy : 0.9837 speed/epoch_sec : 0.0300 speed/samples_per_sec : 1334.9153 \n",
      "epoch: 36\n",
      "train: CE : 0.0750 accuracy : 0.9775 speed/epoch_sec : 1.0596 speed/samples_per_sec : 221.7754 \n",
      "test: CE : 0.0575 accuracy : 0.9839 speed/epoch_sec : 0.0293 speed/samples_per_sec : 1364.6115 \n",
      "epoch: 37\n",
      "train: CE : 0.0730 accuracy : 0.9768 speed/epoch_sec : 1.0850 speed/samples_per_sec : 216.5913 \n",
      "test: CE : 0.0681 accuracy : 0.9804 speed/epoch_sec : 0.0283 speed/samples_per_sec : 1414.7124 \n",
      "epoch: 38\n",
      "train: CE : 0.0781 accuracy : 0.9761 speed/epoch_sec : 1.1484 speed/samples_per_sec : 204.6331 \n",
      "test: CE : 0.0575 accuracy : 0.9842 speed/epoch_sec : 0.0295 speed/samples_per_sec : 1353.9731 \n",
      "epoch: 39\n",
      "train: CE : 0.0746 accuracy : 0.9770 speed/epoch_sec : 0.9861 speed/samples_per_sec : 238.3222 \n",
      "test: CE : 0.0598 accuracy : 0.9820 speed/epoch_sec : 0.0271 speed/samples_per_sec : 1474.9201 \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>â–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–</td></tr><tr><td>CE/train</td><td>â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>accuracy/eval</td><td>â–â–ƒâ–„â–…â–…â–†â–†â–…â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡</td></tr><tr><td>accuracy/train</td><td>â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>speed/epoch_sec/eval</td><td>â–‚â–â–â–â–„â–â–â–â–‚â–â–„â–…â–‚â–‚â–â–…â–â–â–â–â–â–â–â–â–â–‚â–ˆâ–„â–â–â–â–‚â–â–â–â–‚â–â–â–â–</td></tr><tr><td>speed/epoch_sec/train</td><td>â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–„â–„â–‡â–ƒâ–„â–‚â–ƒâ–‚â–„â–ƒâ–‚â–„â–„â–„â–â–â–‚â–„â–‚â–ƒâ–ˆâ–…â–‚â–‚â–ƒâ–‚â–‚â–…â–„â–â–‚â–‚â–ƒâ–‚</td></tr><tr><td>speed/samples_per_sec/eval</td><td>â–†â–ˆâ–‡â–ˆâ–ƒâ–‡â–‡â–ˆâ–†â–‡â–ƒâ–‚â–†â–…â–‡â–ƒâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–â–ƒâ–‡â–‡â–ˆâ–…â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>speed/samples_per_sec/train</td><td>â–…â–…â–†â–„â–…â–‡â–„â–„â–‚â–†â–„â–†â–†â–†â–„â–…â–†â–„â–„â–„â–ˆâ–ˆâ–†â–„â–†â–…â–â–ƒâ–†â–‡â–…â–†â–‡â–ƒâ–„â–‡â–†â–†â–…â–‡</td></tr><tr><td>sys/ram_gb</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>CE/eval</td><td>0.05982</td></tr><tr><td>CE/train</td><td>0.07463</td></tr><tr><td>accuracy/eval</td><td>0.982</td></tr><tr><td>accuracy/train</td><td>0.977</td></tr><tr><td>speed/epoch_sec/eval</td><td>0.02712</td></tr><tr><td>speed/epoch_sec/train</td><td>0.98606</td></tr><tr><td>speed/samples_per_sec/eval</td><td>1474.92009</td></tr><tr><td>speed/samples_per_sec/train</td><td>238.32223</td></tr><tr><td>sys/ram_gb</td><td>1.83504</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_tests</strong> at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/p5zy13dl' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing/runs/p5zy13dl</a><br> View project at: <a href='https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing' target=\"_blank\">https://wandb.ai/nikiwillems9-university-of-bristol/torch%20from%20scratch%20testing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250729_000250-p5zy13dl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_nn(40)\n",
    "train_nn(40, p=0.05)\n",
    "train_nn(40, p=0.1)\n",
    "train_nn(40, p=0.15)\n",
    "train_nn(40, p=0.2)\n",
    "train_nn(40, p=0.25)\n",
    "train_nn(40, p=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DQNenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
